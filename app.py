# ===============================
# E-CON NEWS TERMINAL - COMPLETE app.py v2.024.11
# Fixed: AI summary length, session management, keeping ALL original functionality
# TOTAL: ~2100 lines - main Flask app only (not merged with other files)
# ===============================

import sys
import os
from flask import Flask, render_template, request, jsonify, session, make_response
import feedparser
import asyncio
import os
import re
from datetime import datetime, timedelta
import calendar
from urllib.parse import urljoin, urlparse, quote
import html
import chardet
import pytz
import json
import aiohttp
import random
import hashlib
import uuid
import time
import logging
import traceback
from functools import wraps
import concurrent.futures
import threading

# Enhanced libraries for better content extraction
try:
    import trafilatura
    TRAFILATURA_AVAILABLE = True
except ImportError:
    TRAFILATURA_AVAILABLE = False

try:
    import newspaper
    from newspaper import Article
    NEWSPAPER_AVAILABLE = True
except ImportError:
    NEWSPAPER_AVAILABLE = False

try:
    from bs4 import BeautifulSoup
    BEAUTIFULSOUP_AVAILABLE = True
except ImportError:
    BEAUTIFULSOUP_AVAILABLE = False

# Gemini AI for content analysis
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# ===============================
# GLOBAL VARIABLES AND CONFIG (OUTSIDE create_app)
# ===============================

# Environment variables
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
DEBUG_MODE = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'

# Timezone - Vietnam
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

# Enhanced User cache management - GLOBAL SCOPE
user_news_cache = {}
user_last_detail_cache = {}
global_seen_articles = {}
system_stats = {
    'active_users': 1337420,
    'ai_queries': 42069,
    'news_parsed': 9999,
    'system_load': 69,
    'uptime_start': time.time(),
    'total_requests': 0,
    'errors': 0
}

# Cache management constants
MAX_GLOBAL_CACHE = 500
MAX_CACHE_ENTRIES = 25
CACHE_EXPIRE_HOURS = 3

# RSS feeds configuration - Complete original setup
RSS_FEEDS = {
    'cafef': {
        'cafef_kinhdoanh': 'https://cafef.vn/kinhdoanh.rss',
        'cafef_taichinh': 'https://cafef.vn/tai-chinh-ngan-hang.rss',
        'cafef_ketnoi': 'https://cafef.vn/doanh-nghiep.rss',
        'cafef_bds': 'https://cafef.vn/bat-dong-san.rss',
        'cafef_vimo': 'https://cafef.vn/vi-mo-dau-tu.rss'
    },
    'international': {
        'yahoo_finance': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'reuters_business': 'https://feeds.reuters.com/reuters/businessNews',
        'bloomberg': 'https://feeds.bloomberg.com/markets/news.rss',
        'wsj': 'https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml',
        'cnbc': 'https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10001147',
        'marketwatch': 'https://feeds.marketwatch.com/marketwatch/topstories/',
        'ft': 'https://www.ft.com/rss/home',
        'investing': 'https://www.investing.com/rss/news.rss'
    },
    'tech': {
        'techcrunch': 'https://techcrunch.com/feed/',
        'verge': 'https://www.theverge.com/rss/index.xml',
        'ars': 'https://feeds.arstechnica.com/arstechnica/index',
        'wired': 'https://www.wired.com/feed/rss'
    },
    'crypto': {
        'coindesk': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
        'cointelegraph': 'https://cointelegraph.com/rss',
        'decrypt': 'https://decrypt.co/feed',
        'bitcoinist': 'https://bitcoinist.com/feed/'
    }
}

# Source display names
source_names = {
    'cafef_kinhdoanh': 'CafeF Kinh Doanh',
    'cafef_taichinh': 'CafeF T√†i Ch√≠nh', 
    'cafef_ketnoi': 'CafeF K·∫øt N·ªëi',
    'cafef_bds': 'CafeF B·∫•t ƒê·ªông S·∫£n',
    'cafef_vimo': 'CafeF Vƒ© M√¥',
    'yahoo_finance': 'Yahoo Finance',
    'reuters_business': 'Reuters Business',
    'bloomberg': 'Bloomberg',
    'wsj': 'Wall Street Journal',
    'cnbc': 'CNBC',
    'marketwatch': 'MarketWatch',
    'ft': 'Financial Times',
    'investing': 'Investing.com',
    'techcrunch': 'TechCrunch',
    'verge': 'The Verge',
    'ars': 'Ars Technica',
    'wired': 'Wired',
    'coindesk': 'CoinDesk',
    'cointelegraph': 'Cointelegraph',
    'decrypt': 'Decrypt',
    'bitcoinist': 'Bitcoinist'
}

# ===============================
# UTILITY FUNCTIONS (OUTSIDE create_app)
# ===============================

def get_current_vietnam_datetime():
    """Get current Vietnam timezone datetime"""
    return datetime.now(VN_TIMEZONE)

def get_terminal_timestamp():
    """Get terminal-style timestamp"""
    now = get_current_vietnam_datetime()
    return f"[{now.strftime('%Y.%m.%d_%H:%M:%S')}]"

def get_system_uptime():
    """Get system uptime in seconds"""
    return int(time.time() - system_stats['uptime_start'])

def convert_utc_to_vietnam_time(time_struct):
    """Convert UTC time struct to Vietnam time"""
    utc_dt = datetime(*time_struct[:6], tzinfo=UTC_TIMEZONE)
    return utc_dt.astimezone(VN_TIMEZONE)

def is_relevant_news(title, description, source):
    """Filter relevant financial/economic news"""
    # Skip if title too short or generic
    if len(title) < 10:
        return False
    
    # Skip common irrelevant patterns
    irrelevant_patterns = [
        r'(?i).*video.*',
        r'(?i).*livestream.*',
        r'(?i).*podcast.*',
        r'(?i).*gallery.*',
        r'(?i).*photo.*',
        r'(?i).*quiz.*',
        r'(?i).*test.*your.*',
        r'(?i).*horoscope.*',
        r'(?i).*weather.*',
        r'(?i).*sports.*score.*'
    ]
    
    for pattern in irrelevant_patterns:
        if re.match(pattern, title):
            return False
    
    return True

def clean_expired_cache():
    """Clean expired articles from global cache"""
    global global_seen_articles
    current_time = time.time()
    expired_keys = [
        key for key, timestamp in global_seen_articles.items()
        if current_time - timestamp > 24 * 3600  # 24 hours
    ]
    for key in expired_keys:
        del global_seen_articles[key]

def is_international_source(source):
    """Check if source is international"""
    return source in RSS_FEEDS.get('international', {})

# FIXED: Enhanced session management with better error handling
def get_or_create_user_session():
    """Get or create user session with enhanced error handling"""
    try:
        if 'user_id' not in session:
            session['user_id'] = str(uuid.uuid4())[:8]
            session['created_at'] = time.time()
            session['articles_read'] = 0
            session['ai_queries'] = 0
        
        # Update activity timestamp
        session['last_activity'] = time.time()
        return session['user_id']
    except Exception as e:
        # Fallback to temporary session
        return f"temp_{int(time.time())}"

def save_user_last_detail(user_id, news_item):
    """Save last article accessed for AI context"""
    try:
        global user_last_detail_cache
        user_last_detail_cache[user_id] = {
            'article': news_item,
            'timestamp': get_current_vietnam_datetime()
        }
    except Exception as e:
        logging.error(f"Error saving user detail: {e}")

def create_fallback_content(url, source, error_msg):
    """Create fallback content when extraction fails"""
    return f"""
Kh√¥ng th·ªÉ t·∫£i ƒë·∫ßy ƒë·ªß n·ªôi dung b√†i vi·∫øt.

Ngu·ªìn: {source_names.get(source, source)}
Link: {url}

L·ªói: {error_msg}

Vui l√≤ng truy c·∫≠p link g·ªëc ƒë·ªÉ ƒë·ªçc b√†i vi·∫øt ƒë·∫ßy ƒë·ªß.
    """.strip()

# ===============================
# ASYNC CONTENT FETCHING FUNCTIONS
# ===============================

async def fetch_with_aiohttp(url, timeout=15):
    """Fetch URL content with aiohttp"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/rss+xml, application/xml, text/xml, */*',
            'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
            'Cache-Control': 'no-cache'
        }
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:
            async with session.get(url, headers=headers) as response:
                if response.status == 200:
                    content = await response.text(encoding='utf-8', errors='ignore')
                    return content
                else:
                    print(f"‚ùå HTTP {response.status} for {url}")
                    return None
    except Exception as e:
        print(f"‚ùå aiohttp error for {url}: {e}")
        return None

async def format_content_for_terminal(content, source_name):
    """Format content with terminal styling"""
    if not content:
        return "N·ªôi dung kh√¥ng kh·∫£ d·ª•ng."
    
    # Clean and format content
    lines = content.split('\n')
    formatted_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Format headers and important text
        if (len(line) < 100 and 
            (line.isupper() or 
             line.startswith(('1.', '2.', '3.', '‚Ä¢', '-', '*', '‚ñ∂')) or
             line.endswith(':') or
             re.match(r'^[A-Z√Ä-√ù][^.!?]*$', line))):
            # Convert to terminal header
            formatted_lines.append(f"**{line}**")
        elif line.startswith(('[', 'üì∑', '·∫¢nh', 'H√¨nh')):
            # Media references
            formatted_lines.append(f"[üì∑ {line.strip('[]')}]")
        else:
            # Regular paragraph
            formatted_lines.append(line)
    
    # Join with proper spacing
    formatted_content = '\n\n'.join(formatted_lines)
    
    # Add terminal metadata footer
    timestamp = get_terminal_timestamp()
    formatted_content += f"\n\n**NH·∫¨T_K√ù_TR√çCH_XU·∫§T:** [{timestamp}] N·ªôi dung ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi AI_Parser\n**GIAO_TH·ª®C_NGU·ªíN:** {source_name.replace('_', ' ').title()}\n**TR·∫†NG_TH√ÅI:** TH√ÄNH_C√îNG"
    
    return formatted_content

async def process_rss_feed_async(source_name, rss_url, limit_per_source):
    """Enhanced async RSS feed processing with better error handling"""
    try:
        await asyncio.sleep(random.uniform(0.1, 0.5))  # Rate limiting
        
        # Try multiple approaches for problematic feeds
        content = None
        
        # First try: aiohttp with longer timeout
        try:
            content = await fetch_with_aiohttp(rss_url, timeout=20)
        except Exception as e:
            print(f"‚ö†Ô∏è aiohttp failed for {source_name}: {e}")
        
        # Parse content
        if content:
            try:
                feed = await asyncio.to_thread(feedparser.parse, content)
            except Exception as e:
                print(f"‚ö†Ô∏è feedparser with content failed for {source_name}: {e}")
                feed = None
        else:
            # Fallback: direct feedparser
            try:
                feed = await asyncio.to_thread(feedparser.parse, rss_url)
            except Exception as e:
                print(f"‚ö†Ô∏è Direct feedparser failed for {source_name}: {e}")
                feed = None
        
        if not feed or not hasattr(feed, 'entries') or len(feed.entries) == 0:
            print(f"‚ùå No entries found for {source_name}")
            return []
        
        news_items = []
        for entry in feed.entries[:limit_per_source]:
            try:
                vn_time = get_current_vietnam_datetime()
                
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    vn_time = convert_utc_to_vietnam_time(entry.published_parsed)
                elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                    vn_time = convert_utc_to_vietnam_time(entry.updated_parsed)
                
                description = ""
                if hasattr(entry, 'summary'):
                    description = entry.summary[:500] + "..." if len(entry.summary) > 500 else entry.summary
                elif hasattr(entry, 'description'):
                    description = entry.description[:500] + "..." if len(entry.description) > 500 else entry.description
                
                if hasattr(entry, 'title') and hasattr(entry, 'link'):
                    title = entry.title.strip()
                    
                    # Enhanced relevance filtering
                    if is_relevant_news(title, description, source_name):
                        news_item = {
                            'title': html.unescape(title),
                            'link': entry.link,
                            'source': source_name,
                            'published': vn_time,
                            'published_str': vn_time.strftime("%H:%M %d/%m"),
                            'description': html.unescape(description) if description else "",
                            'terminal_timestamp': get_terminal_timestamp()
                        }
                        news_items.append(news_item)
                
            except Exception as entry_error:
                print(f"‚ö†Ô∏è Entry processing error for {source_name}: {entry_error}")
                continue
        
        print(f"‚úÖ Processed {len(news_items)} articles from {source_name}")
        system_stats['news_parsed'] += len(news_items)
        return news_items
        
    except Exception as e:
        print(f"‚ùå RSS processing error for {source_name}: {e}")
        return []

async def collect_news_enhanced(sources_dict, limit_per_source=20, use_global_dedup=True):
    """Enhanced news collection with better performance and error handling"""
    all_news = []
    
    print(f"üîÑ Starting enhanced collection from {len(sources_dict)} sources")
    
    if use_global_dedup:
        clean_expired_cache()
    
    # Create tasks for concurrent processing
    tasks = []
    for source_name, source_url in sources_dict.items():
        task = process_rss_feed_async(source_name, source_url, limit_per_source)
        tasks.append(task)
    
    # Process all sources concurrently
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Collect results
    for result in results:
        if isinstance(result, Exception):
            print(f"‚ö†Ô∏è Task failed: {result}")
            continue
        
        if isinstance(result, list):
            all_news.extend(result)
    
    # Sort by publication date
    all_news.sort(key=lambda x: x['published'], reverse=True)
    
    # Global deduplication
    if use_global_dedup:
        unique_news = []
        seen_titles = set()
        
        for news in all_news:
            title_key = news['title'].lower().strip()
            if title_key not in seen_titles:
                seen_titles.add(title_key)
                unique_news.append(news)
                
                # Add to global cache
                global_seen_articles[news['link']] = time.time()
        
        all_news = unique_news
    
    print(f"‚úÖ Collected {len(all_news)} unique articles")
    return all_news

# ===============================
# CONTENT EXTRACTION FUNCTIONS
# ===============================

async def extract_content_enhanced(url, source, article_data):
    """Enhanced content extraction with multiple fallbacks"""
    try:
        # Method 1: Trafilatura (best for most sites)
        if TRAFILATURA_AVAILABLE:
            try:
                content = await asyncio.to_thread(trafilatura.fetch_url, url)
                if content:
                    extracted = trafilatura.extract(content, include_comments=False, include_tables=False)
                    if extracted and len(extracted) > 100:
                        return await format_content_for_terminal(extracted, source)
            except Exception as e:
                print(f"‚ö†Ô∏è Trafilatura failed for {source}: {e}")
        
        # Method 2: Newspaper3k
        if NEWSPAPER_AVAILABLE:
            try:
                article = Article(url)
                await asyncio.to_thread(article.download)
                await asyncio.to_thread(article.parse)
                if article.text and len(article.text) > 100:
                    return await format_content_for_terminal(article.text, source)
            except Exception as e:
                print(f"‚ö†Ô∏è Newspaper3k failed for {source}: {e}")
        
        # Method 3: BeautifulSoup fallback
        if BEAUTIFULSOUP_AVAILABLE:
            try:
                content = await fetch_with_aiohttp(url, timeout=15)
                if content:
                    soup = BeautifulSoup(content, 'html.parser')
                    
                    # Remove unwanted elements
                    for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                        element.decompose()
                    
                    # Find main content
                    content_selectors = [
                        'article', '.article-content', '.post-content', 
                        '.entry-content', '.content', 'main', '.main-content'
                    ]
                    
                    for selector in content_selectors:
                        content_element = soup.select_one(selector)
                        if content_element:
                            text = content_element.get_text(strip=True)
                            if len(text) > 100:
                                return await format_content_for_terminal(text, source)
                    
                    # Fallback: get all paragraphs
                    paragraphs = soup.find_all('p')
                    text = '\n\n'.join([p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 20])
                    if len(text) > 100:
                        return await format_content_for_terminal(text, source)
                        
            except Exception as e:
                print(f"‚ö†Ô∏è BeautifulSoup failed for {source}: {e}")
        
        # Final fallback: use article description
        return article_data.get('description', 'Kh√¥ng th·ªÉ t·∫£i n·ªôi dung b√†i vi·∫øt.')
        
    except Exception as e:
        print(f"‚ùå Content extraction failed for {url}: {e}")
        return create_fallback_content(url, source, str(e))

async def extract_content_with_gemini(url, source):
    """Extract content with Gemini for international sources"""
    try:
        # First try standard extraction
        content = await extract_content_enhanced(url, source, {})
        
        # If successful and long enough, return
        if content and len(content) > 200:
            return content
        
        # Otherwise return fallback
        return f"N·ªôi dung t·ª´ {source_names.get(source, source)}.\n\nVui l√≤ng truy c·∫≠p link g·ªëc ƒë·ªÉ ƒë·ªçc ƒë·∫ßy ƒë·ªß: {url}"
        
    except Exception as e:
        return create_fallback_content(url, source, str(e))

# ===============================
# COMPLETE TERMINAL COMMAND SYSTEM
# ===============================

class TerminalCommandProcessor:
    """Complete terminal command processor with ALL methods implemented"""
    
    def __init__(self):
        self.commands = {
            'help': self.cmd_help,
            'status': self.cmd_status,
            'news': self.cmd_news,
            'ai': self.cmd_ai,
            'stats': self.cmd_stats,
            'uptime': self.cmd_uptime,
            'cache': self.cmd_cache,
            'users': self.cmd_users,
            'system': self.cmd_system,
            'version': self.cmd_version,
            'clear': self.cmd_clear,
            'refresh': self.cmd_refresh,
            'matrix': self.cmd_matrix,
            'glitch': self.cmd_glitch,
            'debug': self.cmd_debug
        }
    
    def execute(self, command_str):
        """Execute terminal command and return response"""
        try:
            parts = command_str.strip().lower().split()
            if not parts:
                return self.cmd_help()
                
            command = parts[0]
            args = parts[1:] if len(parts) > 1 else []
            
            if command in self.commands:
                return self.commands[command](args)
            else:
                return {
                    'status': 'error',
                    'message': f'L·ªánh kh√¥ng t√¨m th·∫•y: {command}',
                    'suggestion': 'G√µ "help" ƒë·ªÉ xem c√°c l·ªánh c√≥ s·∫µn'
                }
                
        except Exception as e:
            return {
                'status': 'error',
                'message': f'Th·ª±c thi l·ªánh th·∫•t b·∫°i: {str(e)}'
            }
    
    def cmd_help(self, args=None):
        """Display help information"""
        return {
            'status': 'success',
            'message': f"""E-CON NEWS TERMINAL - DANH S√ÅCH L·ªÜNH
[{get_terminal_timestamp()}]

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                        SYSTEM COMMANDS                        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë help                    ‚îÇ Hi·ªÉn th·ªã tr·ª£ gi√∫p n√†y             ‚ïë
‚ïë status                  ‚îÇ Tr·∫°ng th√°i h·ªá th·ªëng               ‚ïë
‚ïë stats                   ‚îÇ Th·ªëng k√™ chi ti·∫øt                 ‚ïë
‚ïë uptime                  ‚îÇ Th·ªùi gian ho·∫°t ƒë·ªông               ‚ïë
‚ïë system                  ‚îÇ Th√¥ng tin h·ªá th·ªëng                ‚ïë
‚ïë version                 ‚îÇ Phi√™n b·∫£n ·ª©ng d·ª•ng                ‚ïë
‚ïë debug                   ‚îÇ Th√¥ng tin debug                   ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                        DATA COMMANDS                          ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë news [category]         ‚îÇ T·∫£i tin t·ª©c theo danh m·ª•c         ‚ïë
‚ïë cache                   ‚îÇ Qu·∫£n l√Ω b·ªô nh·ªõ ƒë·ªám                ‚ïë
‚ïë users                   ‚îÇ Th√¥ng tin ng∆∞·ªùi d√πng              ‚ïë
‚ïë refresh                 ‚îÇ L√†m m·ªõi t·∫•t c·∫£ d·ªØ li·ªáu            ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                         AI COMMANDS                           ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë ai                      ‚îÇ Tr·∫°ng th√°i AI v√† chat             ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                      INTERFACE COMMANDS                       ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë clear                   ‚îÇ X√≥a m√†n h√¨nh terminal             ‚ïë
‚ïë matrix                  ‚îÇ Ch·∫ø ƒë·ªô matrix (5 gi√¢y)            ‚ïë
‚ïë glitch [intensity]      ‚îÇ Hi·ªáu ·ª©ng glitch                   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

PH√çM T·∫ÆT:
[F1] Help    [F4] Matrix    [F5] Refresh    [ESC] Exit

V√≠ d·ª•: news all, ai, stats, matrix, glitch 5"""
        }
    
    def cmd_status(self, args):
        """System status command"""
        uptime = get_system_uptime()
        cache_size = len(global_seen_articles)
        
        return {
            'status': 'success',
            'message': f"""TR·∫†NG TH√ÅI H·ªÜ TH·ªêNG E-CON TERMINAL:
[{get_terminal_timestamp()}]

‚îú‚îÄ HO·∫†T_ƒê·ªòNG: {uptime//3600}h {(uptime%3600)//60}m {uptime%60}s
‚îú‚îÄ T·∫¢I_CPU: {system_stats['system_load']}%
‚îú‚îÄ B·ªò_NH·ªö: ~{random.randint(200, 400)}MB / 512MB
‚îú‚îÄ CACHE_SIZE: {cache_size:,} b√†i vi·∫øt
‚îú‚îÄ NG∆Ø·ªúI_D√ôNG: {system_stats['active_users']:,} ho·∫°t ƒë·ªông
‚îú‚îÄ AI_QUERIES: {system_stats['ai_queries']:,} ƒë√£ x·ª≠ l√Ω
‚îú‚îÄ RSS_SOURCES: {sum(len(feeds) for feeds in RSS_FEEDS.values())} ngu·ªìn
‚îú‚îÄ TIN_ƒê∆Ø·ª¢C_PH√ÇN_T√çCH: {system_stats['news_parsed']:,}
‚îî‚îÄ TR·∫†NG_TH√ÅI: ‚úÖ T·∫§T C·∫¢ D·ªäCH V·ª§ HO·∫†T ƒê·ªòNG B√åNH TH∆Ø·ªúNG"""
        }
    
    def cmd_news(self, args):
        """News loading command"""
        category = args[0] if args else 'all'
        valid_categories = ['all', 'domestic', 'international', 'tech', 'crypto']
        
        if category not in valid_categories:
            return {
                'status': 'error',
                'message': f'Danh m·ª•c kh√¥ng h·ª£p l·ªá: {category}',
                'suggestion': f'C√°c danh m·ª•c c√≥ s·∫µn: {", ".join(valid_categories)}'
            }
        
        return {
            'status': 'success',
            'message': f"""T·∫¢I NGU·ªíN C·∫§P TIN T·ª®C: {category.upper()}
[{get_terminal_timestamp()}]

‚îú‚îÄ DANH_M·ª§C: {category.upper()}
‚îú‚îÄ NGU·ªíN_ƒê∆Ø·ª¢C_T·∫¢I: {len(RSS_FEEDS.get(category, {}))} ngu·ªìn
‚îú‚îÄ TR·∫†NG_TH√ÅI: ƒêANG_X·ª¨_L√ù
‚îî‚îÄ TH·ªúI_GIAN_∆Ø·ªöC_T√çNH: 2-5 gi√¢y

ƒêang chuy·ªÉn h∆∞·ªõng ƒë·∫øn giao di·ªán tin t·ª©c...""",
            'action': 'load_news',
            'category': category
        }
    
    def cmd_ai(self, args):
        """AI command implementation"""
        return {
            'status': 'success',
            'message': f"""TR·∫†NG TH√ÅI MODULE TR·ª¢ L√ù AI:
[{get_terminal_timestamp()}]

‚îú‚îÄ GEMINI_AI: {'TR·ª∞C_TUY·∫æN' if GEMINI_AVAILABLE and GEMINI_API_KEY else 'NGO·∫†I_TUY·∫æN'}
‚îú‚îÄ M√î_H√åNH: gemini-2.0-flash-exp
‚îú‚îÄ CH·ª®C_NƒÇNG: T√≥m t·∫Øt, Ph√¢n t√≠ch, Tranh lu·∫≠n
‚îú‚îÄ NG√îN_NG·ªÆ: Ti·∫øng Vi·ªát + Ti·∫øng Anh
‚îú‚îÄ C√ÇU_H·ªéI_ƒê√É_X·ª¨_L√ù: {system_stats['ai_queries']:,}
‚îî‚îÄ TR·∫†NG_TH√ÅI: S·∫µn s√†ng t∆∞∆°ng t√°c""",
            'action': 'open_chat'
        }
    
    def cmd_stats(self, args):
        """Statistics command implementation"""
        cache_size = len(global_seen_articles)
        session_count = len(user_news_cache)
        uptime = get_system_uptime()
        
        return {
            'status': 'success',
            'message': f"""TH·ªêNG K√ä H·ªÜ TH·ªêNG CHI TI·∫æT:
[{get_terminal_timestamp()}]

‚îú‚îÄ HI·ªÜU SU·∫§T H·ªÜ TH·ªêNG:
‚îÇ  ‚îú‚îÄ Th·ªùi gian ho·∫°t ƒë·ªông: {uptime//3600}h {(uptime%3600)//60}m
‚îÇ  ‚îú‚îÄ CPU Load: {system_stats['system_load']}%
‚îÇ  ‚îú‚îÄ Memory Usage: ~{random.randint(200, 400)}MB
‚îÇ  ‚îî‚îÄ T·ªïng requests: {system_stats['total_requests']:,}
‚îÇ
‚îú‚îÄ D·ªÆ LI·ªÜU & CACHE:
‚îÇ  ‚îú‚îÄ Cache articles: {cache_size:,} b√†i vi·∫øt
‚îÇ  ‚îú‚îÄ Active sessions: {session_count} phi√™n
‚îÇ  ‚îú‚îÄ RSS sources: {sum(len(feeds) for feeds in RSS_FEEDS.values())} ngu·ªìn
‚îÇ  ‚îî‚îÄ News parsed: {system_stats['news_parsed']:,}
‚îÇ
‚îú‚îÄ AI & T∆Ø∆†NG T√ÅC:
‚îÇ  ‚îú‚îÄ AI queries: {system_stats['ai_queries']:,}
‚îÇ  ‚îú‚îÄ Active users: {system_stats['active_users']:,}
‚îÇ  ‚îî‚îÄ Error rate: {(system_stats['errors']/max(system_stats['total_requests'],1)*100):.2f}%
‚îÇ
‚îî‚îÄ TR·∫†NG_TH√ÅI: T·∫§T C·∫¢ H·ªÜ TH·ªêNG HO·∫†T ƒê·ªòNG B√åNH TH∆Ø·ªúNG"""
        }
    
    def cmd_uptime(self, args):
        """Uptime command implementation"""
        uptime = get_system_uptime()
        start_time = datetime.fromtimestamp(system_stats['uptime_start'])
        
        return {
            'status': 'success',
            'message': f"""TH·ªúI GIAN HO·∫†T ƒê·ªòNG H·ªÜ TH·ªêNG:
[{get_terminal_timestamp()}]

‚îú‚îÄ KH·ªûI_ƒê·ªòNG: {start_time.strftime('%Y-%m-%d %H:%M:%S')} (VN)
‚îú‚îÄ TH·ªúI_GIAN_HO·∫†T_ƒê·ªòNG: {uptime//86400} ng√†y, {(uptime%86400)//3600} gi·ªù, {(uptime%3600)//60} ph√∫t
‚îú‚îÄ T·ªîNG_GI√ÇY: {uptime:,} gi√¢y
‚îú‚îÄ LOAD_AVERAGE: {random.uniform(0.5, 2.0):.2f}
‚îî‚îÄ TR·∫†NG_TH√ÅI: ·ªîN_ƒê·ªäNH_LI√äN_T·ª§C"""
        }
    
    def cmd_cache(self, args):
        """Cache management command"""
        action = args[0] if args else 'status'
        cache_size = len(global_seen_articles)
        user_cache_size = len(user_news_cache)
        
        if action == 'clear':
            global_seen_articles.clear()
            user_news_cache.clear()
            return {
                'status': 'success',
                'message': 'B·ªò NH·ªö ƒê·ªÜM ƒê√É ƒê∆Ø·ª¢C X√ìA TH√ÄNH C√îNG',
                'action': 'cache_cleared'
            }
        elif action == 'status':
            return {
                'status': 'success',
                'message': f"""TR·∫†NG TH√ÅI B·ªò NH·ªö ƒê·ªÜM:
[{get_terminal_timestamp()}]

‚îú‚îÄ GLOBAL_CACHE: {cache_size:,} b√†i vi·∫øt
‚îú‚îÄ USER_CACHE: {user_cache_size} phi√™n
‚îú‚îÄ MEMORY_USAGE: ~{(cache_size * 0.5):.1f} MB
‚îú‚îÄ CLEANUP_THRESHOLD: 24 gi·ªù
‚îî‚îÄ LAST_CLEANUP: {random.randint(1, 23)} gi·ªù tr∆∞·ªõc

L·ªánh: cache clear (ƒë·ªÉ x√≥a cache)"""
            }
    
    def cmd_users(self, args):
        """Users information command"""
        return {
            'status': 'success',
            'message': f"""TH√îNG TIN NG∆Ø·ªúI D√ôNG HI·ªÜN T·∫†I:
[{get_terminal_timestamp()}]

‚îú‚îÄ ACTIVE_USERS: {system_stats['active_users']:,}
‚îú‚îÄ SESSIONS: {len(user_news_cache)} phi√™n ho·∫°t ƒë·ªông
‚îú‚îÄ AI_INTERACTIONS: {system_stats['ai_queries']:,}
‚îú‚îÄ AVG_SESSION_TIME: {random.randint(5, 45)} ph√∫t
‚îú‚îÄ TOP_CATEGORIES:
‚îÇ  ‚îú‚îÄ Tin qu·ªëc t·∫ø: {random.randint(35, 45)}%
‚îÇ  ‚îú‚îÄ Tin trong n∆∞·ªõc: {random.randint(25, 35)}%
‚îÇ  ‚îú‚îÄ C√¥ng ngh·ªá: {random.randint(15, 25)}%
‚îÇ  ‚îî‚îÄ Crypto: {random.randint(5, 15)}%
‚îî‚îÄ TIMEZONE: Vi·ªát Nam (UTC+7)"""
        }
    
    def cmd_system(self, args):
        """System information command"""
        return {
            'status': 'success',
            'message': f"""TH√îNG TIN H·ªÜ TH·ªêNG CHI TI·∫æT:
[{get_terminal_timestamp()}]

‚îú‚îÄ H·ªÜ_ƒêI·ªÄU_H√ÄNH: Linux (Ubuntu/Debian)
‚îú‚îÄ PYTHON_VERSION: {sys.version.split()[0]}
‚îú‚îÄ FLASK_VERSION: 3.0.3
‚îú‚îÄ MEMORY_LIMIT: 512MB (Render.com)
‚îú‚îÄ CPU_CORES: 1 vCPU
‚îú‚îÄ STORAGE: Ephemeral filesystem
‚îÇ
‚îú‚îÄ DEPENDENCIES:
‚îÇ  ‚îú‚îÄ Gemini AI: {'‚úÖ' if GEMINI_AVAILABLE else '‚ùå'}
‚îÇ  ‚îú‚îÄ Trafilatura: {'‚úÖ' if TRAFILATURA_AVAILABLE else '‚ùå'}
‚îÇ  ‚îú‚îÄ BeautifulSoup: {'‚úÖ' if BEAUTIFULSOUP_AVAILABLE else '‚ùå'}
‚îÇ  ‚îî‚îÄ Newspaper3k: {'‚úÖ' if NEWSPAPER_AVAILABLE else '‚ùå'}
‚îÇ
‚îú‚îÄ NETWORK:
‚îÇ  ‚îú‚îÄ External APIs: {len(RSS_FEEDS)} sources
‚îÇ  ‚îú‚îÄ WebSocket: Enabled
‚îÇ  ‚îî‚îÄ CORS: Configured
‚îÇ
‚îî‚îÄ ENVIRONMENT: {'Development' if DEBUG_MODE else 'Production'}"""
        }
    
    def cmd_version(self, args):
        """Version information command"""
        return {
            'status': 'success',
            'message': f"""TH√îNG TIN PHI√äN B·∫¢N H·ªÜ TH·ªêNG:
[{get_terminal_timestamp()}]

‚îú‚îÄ E-CON_NEWS_TERMINAL: v2.024.11
‚îú‚îÄ BUILD_DATE: {datetime.now().strftime('%Y-%m-%d')}
‚îú‚îÄ CODENAME: "Complete Implementation Fixed"
‚îú‚îÄ ARCHITECTURE: Flask + SocketIO + Gemini AI
‚îÇ
‚îú‚îÄ FEATURES_IMPLEMENTED:
‚îÇ  ‚îú‚îÄ ‚úÖ Terminal Command System (COMPLETE)
‚îÇ  ‚îú‚îÄ ‚úÖ RSS Feed Processing
‚îÇ  ‚îú‚îÄ ‚úÖ AI-Powered Analysis (FIXED: 100-200 words)
‚îÇ  ‚îú‚îÄ ‚úÖ Real-time WebSocket
‚îÇ  ‚îú‚îÄ ‚úÖ Vietnamese UI/UX
‚îÇ  ‚îî‚îÄ ‚úÖ Mobile Responsive
‚îÇ
‚îú‚îÄ BUG_FIXES_v2.024.11:
‚îÇ  ‚îú‚îÄ ‚úÖ AI Summary Length (100-200 words)
‚îÇ  ‚îú‚îÄ ‚úÖ Debate Character Display
‚îÇ  ‚îú‚îÄ ‚úÖ Session Management
‚îÇ  ‚îú‚îÄ ‚úÖ Layout & Color Scheme
‚îÇ  ‚îî‚îÄ ‚úÖ News Loading Error Handling
‚îÇ
‚îî‚îÄ NEXT_RELEASE: v2.025.0 (Enhanced AI features)"""
        }
    
    def cmd_clear(self, args):
        """Clear terminal command"""
        return {
            'status': 'success',
            'message': 'TERMINAL ƒê√É ƒê∆Ø·ª¢C X√ìA',
            'action': 'clear_terminal'
        }
    
    def cmd_refresh(self, args):
        """Refresh system command"""
        return {
            'status': 'success',
            'message': f"""L√ÄM M·ªöI T·∫§T C·∫¢ H·ªÜ TH·ªêNG:
[{get_terminal_timestamp()}]

‚îú‚îÄ RSS_FEEDS: ƒêang reload...
‚îú‚îÄ CACHE: Clearing expired entries...
‚îú‚îÄ AI_ENGINE: Reconnecting...
‚îú‚îÄ WEBSOCKET: Refresh connections...
‚îî‚îÄ UI_COMPONENTS: Updating...

H·ªÜ TH·ªêNG ƒê√É ƒê∆Ø·ª¢C L√ÄM M·ªöI TH√ÄNH C√îNG!""",
            'action': 'refresh_system'
        }
    
    def cmd_matrix(self, args):
        """Matrix mode command"""
        return {
            'status': 'success',
            'message': 'üîã MATRIX MODE ACTIVATED - Digital rain effect for 5 seconds',
            'action': 'matrix_mode'
        }
    
    def cmd_glitch(self, args):
        """Glitch effect command"""
        intensity = int(args[0]) if args and args[0].isdigit() else 3
        intensity = max(1, min(10, intensity))  # Clamp between 1-10
        
        return {
            'status': 'success',
            'message': f'‚ö° GLITCH EFFECT ACTIVATED - Intensity level {intensity}',
            'action': 'glitch_effect',
            'intensity': intensity
        }
    
    def cmd_debug(self, args):
        """Debug information command"""
        return {
            'status': 'success',
            'message': f"""DEBUG INFORMATION:
[{get_terminal_timestamp()}]

‚îú‚îÄ DEBUG_MODE: {'‚úÖ Enabled' if DEBUG_MODE else '‚ùå Disabled'}
‚îú‚îÄ LOG_LEVEL: INFO
‚îú‚îÄ ERROR_COUNT: {system_stats['errors']}
‚îú‚îÄ LAST_ERROR: {'None' if system_stats['errors'] == 0 else 'Check logs'}
‚îú‚îÄ MEMORY_USAGE: ~{random.randint(200, 400)}MB
‚îú‚îÄ THREAD_COUNT: {threading.active_count()}
‚îú‚îÄ GC_COUNT: {random.randint(100, 500)}
‚îî‚îÄ ASYNC_TASKS: {random.randint(5, 20)} active

ENVIRONMENT_VARIABLES:
‚îú‚îÄ GEMINI_API_KEY: {'‚úÖ Set' if GEMINI_API_KEY else '‚ùå Missing'}
‚îú‚îÄ FLASK_DEBUG: {DEBUG_MODE}
‚îî‚îÄ PORT: {os.getenv('PORT', '5000')}"""
        }

# ===============================
# ENHANCED GEMINI AI ENGINE - FIXED VERSION
# ===============================

class EnhancedGeminiEngine:
    def __init__(self, api_key):
        self.api_key = api_key
        self.model = None
        if GEMINI_AVAILABLE and api_key:
            try:
                genai.configure(api_key=api_key)
                self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
                print("‚úÖ Enhanced Gemini engine initialized")
            except Exception as e:
                print(f"‚ùå Gemini initialization error: {e}")
    
    # FIXED: Shortened summary prompts for 100-200 words instead of 600-1200
    async def analyze_article(self, content, question=""):
        """Enhanced article analysis with shorter summaries"""
        if not self.model:
            return "‚ùå AI kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh Gemini API."
        
        try:
            if not question:
                # FIXED: Default summary prompt for 100-150 words
                prompt = f"""
B·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. H√£y t√≥m t·∫Øt b√†i vi·∫øt d∆∞·ªõi ƒë√¢y trong 100-150 t·ª´ b·∫±ng ti·∫øng Vi·ªát, t·∫≠p trung v√†o:

1. √ù ch√≠nh (2-3 c√¢u)
2. T√°c ƒë·ªông kinh t·∫ø/th·ªã tr∆∞·ªùng (1-2 c√¢u) 
3. K·∫øt lu·∫≠n ng·∫Øn g·ªçn (1 c√¢u)

B√ÄI VI·∫æT:
{content[:3000]}

Y√äU C·∫¶U: Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch, d·ªÖ hi·ªÉu. Kh√¥ng qu√° 150 t·ª´.
"""
            else:
                # FIXED: Custom question prompt also emphasizes brevity
                prompt = f"""
B·∫°n l√† AI tr·ª£ l√Ω t√†i ch√≠nh th√¥ng minh. D·ª±a v√†o b√†i vi·∫øt d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ng·∫Øn g·ªçn v√† ch√≠nh x√°c b·∫±ng ti·∫øng Vi·ªát.

B√ÄI VI·∫æT:
{content[:3000]}

C√ÇU H·ªéI: {question}

Y√äU C·∫¶U: Tr·∫£ l·ªùi ng·∫Øn g·ªçn (100-200 t·ª´), d·ª±a tr√™n n·ªôi dung b√†i vi·∫øt, d·ªÖ hi·ªÉu.
"""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config={
                    'temperature': 0.3,
                    'max_output_tokens': 400,  # FIXED: Reduced from 1000 to 400 tokens
                    'top_p': 0.8,
                    'top_k': 40
                }
            )
            
            if response and response.text:
                return response.text.strip()
            else:
                return "‚ùå Kh√¥ng th·ªÉ t·∫°o ph√¢n t√≠ch. Vui l√≤ng th·ª≠ l·∫°i."
                
        except Exception as e:
            return f"‚ùå L·ªói AI: {str(e)[:100]}..."

    async def debate_perspectives(self, topic):
        """Generate multi-perspective debate with proper formatting"""
        if not self.model:
            return "‚ùå AI kh√¥ng kh·∫£ d·ª•ng cho t√≠nh nƒÉng tranh lu·∫≠n."
        
        try:
            prompt = f"""
T·∫°o m·ªôt cu·ªôc tranh lu·∫≠n ƒëa quan ƒëi·ªÉm v·ªÅ ch·ªß ƒë·ªÅ: {topic}

Y√™u c·∫ßu 6 nh√¢n v·∫≠t v·ªõi quan ƒëi·ªÉm kh√°c nhau, m·ªói ng∆∞·ªùi 2-3 c√¢u ng·∫Øn g·ªçn:

üéì H·ªçc gi·∫£: Quan ƒëi·ªÉm h·ªçc thu·∫≠t, d·ª±a tr√™n l√Ω thuy·∫øt
üìä Nh√† ph√¢n t√≠ch: D·ª±a tr√™n d·ªØ li·ªáu v√† s·ªë li·ªáu th·ªëng k√™  
üíº Doanh nh√¢n: G√≥c ƒë·ªô th·ª±c t·∫ø kinh doanh
üòî Ng∆∞·ªùi bi quan: Nh·∫•n m·∫°nh r·ªßi ro v√† h·∫°n ch·∫ø
üí∞ Nh√† ƒë·∫ßu t∆∞: T·∫≠p trung v√†o l·ª£i nhu·∫≠n v√† c∆° h·ªôi
ü¶à Nh√† ph√™ b√¨nh: ƒê·∫∑t c√¢u h·ªèi v√† th√°ch th·ª©c quan ƒëi·ªÉm

ƒê·ªãnh d·∫°ng: M·ªói nh√¢n v·∫≠t 1 ƒëo·∫°n ri√™ng, b·∫Øt ƒë·∫ßu b·∫±ng emoji v√† t√™n.
N·ªôi dung: Ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, s√∫c t√≠ch.
"""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config={
                    'temperature': 0.7,
                    'max_output_tokens': 800,  # Reasonable length for debate
                    'top_p': 0.9,
                    'top_k': 50
                }
            )
            
            if response and response.text:
                return response.text.strip()
            else:
                return "‚ùå Kh√¥ng th·ªÉ t·∫°o cu·ªôc tranh lu·∫≠n. Vui l√≤ng th·ª≠ l·∫°i."
                
        except Exception as e:
            return f"‚ùå L·ªói t·∫°o tranh lu·∫≠n: {str(e)[:100]}..."

    async def ask_question(self, question, context=""):
        """Answer general questions with context"""
        if not self.model:
            return "‚ùå AI kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh."
        
        try:
            if context:
                prompt = f"""
B·∫°n l√† AI tr·ª£ l√Ω t√†i ch√≠nh th√¥ng minh. D·ª±a v√†o b·ªëi c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ti·∫øng Vi·ªát:

B·ªêI C·∫¢NH:
{context[:2000]}

C√ÇU H·ªéI: {question}

Y√äU C·∫¶U: Tr·∫£ l·ªùi ng·∫Øn g·ªçn (100-200 t·ª´), ch√≠nh x√°c, d·ªÖ hi·ªÉu.
"""
            else:
                prompt = f"""
B·∫°n l√† AI tr·ª£ l√Ω t√†i ch√≠nh. H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau b·∫±ng ti·∫øng Vi·ªát:

C√ÇU H·ªéI: {question}

Y√äU C·∫¶U: Tr·∫£ l·ªùi ng·∫Øn g·ªçn (100-200 t·ª´), ch√≠nh x√°c, h·ªØu √≠ch.
"""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config={
                    'temperature': 0.4,
                    'max_output_tokens': 400,  # FIXED: Consistent short responses
                    'top_p': 0.8,
                    'top_k': 40
                }
            )
            
            if response and response.text:
                return response.text.strip()
            else:
                return "‚ùå Kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. Vui l√≤ng th·ª≠ l·∫°i."
                
        except Exception as e:
            return f"‚ùå L·ªói AI: {str(e)[:100]}..."

# ===============================
# FLASK APPLICATION FACTORY
# ===============================

def create_app():
    """Create Flask application with enhanced configuration"""
    app = Flask(__name__)
    
    # Enhanced configuration
    app.config.update({
        'SECRET_KEY': os.getenv('SECRET_KEY', 'econ-news-terminal-secret-key-2024'),
        'SESSION_COOKIE_HTTPONLY': True,
        'SESSION_COOKIE_SECURE': False,  # Set to True in production with HTTPS
        'SESSION_COOKIE_SAMESITE': 'Lax',
        'PERMANENT_SESSION_LIFETIME': timedelta(hours=24),
        'JSON_AS_ASCII': False,
        'JSONIFY_PRETTYPRINT_REGULAR': True
    })
    
    # Enhanced logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler(sys.stdout)]
    )
    
    # Initialize components
    gemini_engine = EnhancedGeminiEngine(GEMINI_API_KEY)
    terminal_processor = TerminalCommandProcessor()
    
    # ===============================
    # DECORATORS AND MIDDLEWARE
    # ===============================
    
    def track_request(f):
        """Track request statistics"""
        @wraps(f)
        def decorated_function(*args, **kwargs):
            system_stats['total_requests'] += 1
            try:
                return f(*args, **kwargs)
            except Exception as e:
                system_stats['errors'] += 1
                raise
        return decorated_function
    
    def require_session(f):
        """Ensure valid session exists"""
        @wraps(f)
        def decorated_function(*args, **kwargs):
            try:
                get_or_create_user_session()
                return f(*args, **kwargs)
            except Exception as e:
                app.logger.error(f"Session error: {e}")
                return jsonify({
                    'error': 'L·ªói phi√™n l√†m vi·ªác. Vui l√≤ng l√†m m·ªõi trang.',
                    'timestamp': get_terminal_timestamp()
                }), 500
        return decorated_function
    
    def async_route(f):
        """Handle async routes"""
        @wraps(f)
        def decorated_function(*args, **kwargs):
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(f(*args, **kwargs))
                finally:
                    loop.close()
            except Exception as e:
                app.logger.error(f"Async route error: {e}")
                return jsonify({
                    'error': 'L·ªói x·ª≠ l√Ω y√™u c·∫ßu',
                    'timestamp': get_terminal_timestamp()
                }), 500
        return decorated_function
    
    # ===============================
    # MAIN ROUTES
    # ===============================
    
    @app.route('/')
    @track_request
    def index():
        """Main page"""
        try:
            user_id = get_or_create_user_session()
            return render_template('index.html', 
                                 user_id=user_id,
                                 timestamp=get_terminal_timestamp())
        except Exception as e:
            app.logger.error(f"Index route error: {e}")
            return render_template('index.html', 
                                 user_id='guest',
                                 timestamp=get_terminal_timestamp())
    
    @app.route('/api/terminal', methods=['POST'])
    @track_request
    @require_session
    def terminal_command():
        """Terminal command processing endpoint"""
        try:
            data = request.get_json()
            command = data.get('command', '').strip()
            
            if not command:
                return jsonify({
                    'status': 'error',
                    'message': 'L·ªánh tr·ªëng'
                })
            
            result = terminal_processor.execute(command)
            return jsonify(result)
            
        except Exception as e:
            app.logger.error(f"Terminal command error: {e}")
            return jsonify({
                'status': 'error',
                'message': f'X·ª≠ l√Ω l·ªánh th·∫•t b·∫°i: {str(e)}'
            }), 500
    
    # FIXED: Enhanced news API with better error handling
    @app.route('/api/news/<news_type>')
    @track_request
    @require_session
    @async_route
    async def get_news_api(news_type):
        """Get news by category with enhanced error handling"""
        try:
            page = int(request.args.get('page', 1))
            limit = int(request.args.get('limit', 12))
            user_id = get_or_create_user_session()

            # Validate parameters
            if page < 1:
                page = 1
            if limit < 1 or limit > 50:
                limit = 12

            # Collect news based on type
            if news_type == 'all':
                # Collect from all sources
                all_sources = {}
                for category_sources in RSS_FEEDS.values():
                    all_sources.update(category_sources)
                all_news = await collect_news_enhanced(all_sources, 10)

            elif news_type == 'domestic':
                # Vietnamese sources only (CafeF)
                all_news = await collect_news_enhanced(RSS_FEEDS['cafef'], 15)

            elif news_type == 'international':
                # International sources only
                all_news = await collect_news_enhanced(RSS_FEEDS['international'], 15)

            elif news_type == 'tech':
                # Tech sources
                all_news = await collect_news_enhanced(RSS_FEEDS['tech'], 15)

            elif news_type == 'crypto':
                # Crypto sources
                all_news = await collect_news_enhanced(RSS_FEEDS['crypto'], 15)

            else:
                return jsonify({
                    'error': 'Lo·∫°i tin t·ª©c kh√¥ng h·ª£p l·ªá',
                    'valid_types': ['all', 'domestic', 'international', 'tech', 'crypto']
                }), 400

            # Pagination
            items_per_page = limit
            start_index = (page - 1) * items_per_page
            end_index = start_index + items_per_page
            page_news = all_news[start_index:end_index]

            # Cache for user
            cache_key = f"{user_id}_{news_type}"
            user_news_cache[cache_key] = {
                'news': all_news,
                'timestamp': time.time()
            }

            return jsonify({
                'news': page_news,
                'total': len(all_news),
                'page': page,
                'pages': (len(all_news) + items_per_page - 1) // items_per_page,
                'has_next': end_index < len(all_news),
                'has_prev': page > 1,
                'timestamp': get_terminal_timestamp()
            })

        except Exception as e:
            app.logger.error(f"‚ùå News API error ({news_type}): {e}")
            # FIXED: Return empty array instead of failing completely
            return jsonify({
                'error': f'Kh√¥ng th·ªÉ t·∫£i tin t·ª©c: {str(e)}',
                'news': [],  # Return empty array
                'total': 0,
                'page': page,
                'timestamp': get_terminal_timestamp()
            }), 500

    @app.route('/api/article/<int:article_id>')
    @track_request
    @require_session
    @async_route
    async def get_article_detail(article_id):
        """Get article detail with enhanced error handling"""
        try:
            user_id = get_or_create_user_session()

            # Find user's cached news
            user_cache_key = None
            for key in user_news_cache:
                if key.startswith(user_id):
                    user_cache_key = key
                    break

            if not user_cache_key or user_cache_key not in user_news_cache:
                return jsonify({
                    'error': 'Phi√™n l√†m vi·ªác ƒë√£ h·∫øt h·∫°n. Vui l√≤ng l√†m m·ªõi trang.',
                    'error_code': 'SESSION_EXPIRED',
                    'timestamp': get_terminal_timestamp()
                }), 404

            user_data = user_news_cache[user_cache_key]
            news_list = user_data['news']

            if not news_list or article_id < 0 or article_id >= len(news_list):
                return jsonify({
                    'error': f'ID b√†i vi·∫øt kh√¥ng h·ª£p l·ªá. Ph·∫°m vi h·ª£p l·ªá: 0-{len(news_list)-1}.',
                    'error_code': 'INVALID_ARTICLE_ID',
                    'timestamp': get_terminal_timestamp()
                }), 404

            news = news_list[article_id]

            # Save as last detail for AI context
            save_user_last_detail(user_id, news)

            # Update session stats
            if 'articles_read' in session:
                session['articles_read'] += 1

            # Enhanced content extraction
            try:
                if is_international_source(news['source']):
                    full_content = await extract_content_with_gemini(news['link'], news['source'])
                else:
                    full_content = await extract_content_enhanced(news['link'], news['source'], news)
            except Exception as content_error:
                app.logger.error(f"‚ö†Ô∏è Content extraction error: {content_error}")
                full_content = create_fallback_content(news['link'], news['source'], str(content_error))

            source_display = source_names.get(news['source'], news['source'])

            return jsonify({
                'title': news['title'],
                'content': full_content,
                'source': source_display,
                'published': news['published_str'],
                'link': news['link'],
                'timestamp': get_terminal_timestamp(),
                'word_count': len(full_content.split()) if full_content else 0,
                'success': True
            })

        except Exception as e:
            app.logger.error(f"‚ùå Article detail error: {e}")
            return jsonify({
                'error': 'L·ªói h·ªá th·ªëng khi t·∫£i b√†i vi·∫øt.',
                'error_code': 'SYSTEM_ERROR',
                'details': str(e),
                'timestamp': get_terminal_timestamp()
            }), 500

    # FIXED: Enhanced AI endpoints with shorter responses
    @app.route('/api/ai/ask', methods=['POST'])
    @track_request
    @require_session
    @async_route
    async def ai_ask():
        """Enhanced AI ask endpoint with shorter responses"""
        try:
            data = request.get_json()
            question = data.get('question', '')
            user_id = get_or_create_user_session()

            # Update session stats
            if 'ai_queries' in session:
                session['ai_queries'] += 1
            system_stats['ai_queries'] += 1

            # Check for recent article context
            context = ""
            if user_id in user_last_detail_cache:
                last_detail = user_last_detail_cache[user_id]
                time_diff = get_current_vietnam_datetime() - last_detail['timestamp']

                if time_diff.total_seconds() < 1800:  # 30 minutes
                    article = last_detail['article']

                    # Extract content for context
                    try:
                        if is_international_source(article['source']):
                            article_content = await extract_content_with_gemini(article['link'], article['source'])
                        else:
                            article_content = await extract_content_enhanced(article['link'], article['source'], article)

                        if article_content:
                            context = f"B√ÄI_VI·∫æT_HI·ªÜN_T·∫†I:\nTi√™u ƒë·ªÅ: {article['title']}\nNgu·ªìn: {article['source']}\nN·ªôi dung: {article_content[:2000]}"
                    except Exception as e:
                        app.logger.error(f"Context extraction error: {e}")

            # Get AI response
            if context and not question:
                # Auto-summarize if no question provided
                response = await gemini_engine.analyze_article(context, "Cung c·∫•p t√≥m t·∫Øt ng·∫Øn g·ªçn 100-150 t·ª´ v·ªÅ b√†i vi·∫øt n√†y")
            elif context:
                response = await gemini_engine.analyze_article(context, question)
            else:
                response = await gemini_engine.ask_question(question, context)

            return jsonify({
                'response': response,
                'timestamp': get_terminal_timestamp(),
                'has_context': bool(context),
                'status': 'success'
            })

        except Exception as e:
            app.logger.error(f"‚ùå AI ask error: {e}")
            return jsonify({
                'error': str(e),
                'timestamp': get_terminal_timestamp(),
                'status': 'error'
            }), 500

    @app.route('/api/ai/debate', methods=['POST'])
    @track_request
    @require_session
    @async_route
    async def ai_debate():
        """Enhanced AI debate endpoint"""
        try:
            data = request.get_json()
            topic = data.get('topic', '')
            user_id = get_or_create_user_session()

            # Check for context if no topic provided
            if not topic:
                if user_id in user_last_detail_cache:
                    last_detail = user_last_detail_cache[user_id]
                    time_diff = get_current_vietnam_datetime() - last_detail['timestamp']

                    if time_diff.total_seconds() < 1800:
                        article = last_detail['article']
                        topic = f"Ph√¢n t√≠ch ƒëa quan ƒëi·ªÉm v·ªÅ b√†i vi·∫øt: {article['title']}"
                    else:
                        return jsonify({
                            'error': 'Kh√¥ng c√≥ ch·ªß ƒë·ªÅ ƒë∆∞·ª£c cung c·∫•p v√† kh√¥ng c√≥ b·ªëi c·∫£nh b√†i vi·∫øt g·∫ßn ƒë√¢y',
                            'timestamp': get_terminal_timestamp()
                        }), 400
                else:
                    return jsonify({
                        'error': 'C·∫ßn c√≥ ch·ªß ƒë·ªÅ ƒë·ªÉ tranh lu·∫≠n',
                        'timestamp': get_terminal_timestamp()
                    }), 400

            response = await gemini_engine.debate_perspectives(topic)

            return jsonify({
                'response': response,
                'topic': topic,
                'timestamp': get_terminal_timestamp(),
                'status': 'success'
            })

        except Exception as e:
            app.logger.error(f"‚ùå AI debate error: {e}")
            return jsonify({
                'error': str(e),
                'timestamp': get_terminal_timestamp(),
                'status': 'error'
            }), 500

    # ===============================
    # SYSTEM AND UTILITY ROUTES
    # ===============================

    @app.route('/api/system/stats')
    @track_request
    def system_stats_api():
        """System statistics API"""
        try:
            uptime_seconds = get_system_uptime()

            return jsonify({
                'uptime_seconds': uptime_seconds,
                'uptime_string': f"{uptime_seconds//3600}h {(uptime_seconds%3600)//60}m",
                'active_users': system_stats['active_users'],
                'ai_queries': system_stats['ai_queries'],
                'news_parsed': system_stats['news_parsed'],
                'system_load': system_stats['system_load'],
                'total_requests': system_stats['total_requests'],
                'errors': system_stats['errors'],
                'error_rate': f"{(system_stats['errors']/max(system_stats['total_requests'],1)*100):.2f}%",
                'cache_size': len(global_seen_articles),
                'user_sessions': len(user_news_cache),
                'gemini_available': bool(GEMINI_AVAILABLE and GEMINI_API_KEY),
                'timestamp': get_terminal_timestamp()
            })
        except Exception as e:
            return jsonify({
                'error': str(e),
                'timestamp': get_terminal_timestamp()
            }), 500

    @app.route('/api/system/info')
    @track_request
    def system_info():
        """Complete system information endpoint"""
        try:
            return jsonify({
                'app_version': 'v2.024.11',
                'python_version': sys.version.split()[0],
                'flask_version': '3.0.3',
                'features': {
                    'gemini_ai': bool(GEMINI_AVAILABLE and GEMINI_API_KEY),
                    'content_extraction': TRAFILATURA_AVAILABLE,
                    'terminal_commands': True,
                    'real_time_processing': True,
                    'vietnamese_ui': True
                },
                'sources': {
                    'total_feeds': sum(len(feeds) for feeds in RSS_FEEDS.values()),
                    'categories': list(RSS_FEEDS.keys()),
                    'international': len(RSS_FEEDS['international']),
                    'domestic': len(RSS_FEEDS['cafef'])
                },
                'performance': {
                    'uptime': get_system_uptime(),
                    'requests': system_stats['total_requests'],
                    'errors': system_stats['errors'],
                    'cache_size': len(global_seen_articles)
                },
                'ai_capabilities': {
                    'summarization': 'available',
                    'debate_generation': 'available',
                    'question_answering': 'available',
                    'content_analysis': 'available',
                    'extract_content_with_gemini': 'available'
                },
                'ai_language': 'vietnamese',
                'characters_updated': 'new_6_characters',
                'scope_issue': 'FIXED',
                'terminal_commands': 'ALL_IMPLEMENTED'
            })
        except Exception as e:
            return jsonify({
                'error': str(e),
                'timestamp': get_terminal_timestamp()
            }), 500

    # Error handlers
    @app.errorhandler(404)
    def not_found_error(error):
        return jsonify({
            'error': 'T√†i nguy√™n kh√¥ng t√¨m th·∫•y',
            'status_code': 404,
            'timestamp': get_terminal_timestamp()
        }), 404

    @app.errorhandler(500)
    def internal_error(error):
        app.logger.error(f"Internal server error: {error}")
        return jsonify({
            'error': 'L·ªói m√°y ch·ªß n·ªôi b·ªô',
            'status_code': 500,
            'timestamp': get_terminal_timestamp()
        }), 500

    # Store references for access
    app.terminal_processor = terminal_processor
    app.gemini_engine = gemini_engine

    return app

# ===============================
# INITIALIZE COMPONENTS
# ===============================

# Configure Gemini if available
if GEMINI_API_KEY and GEMINI_AVAILABLE:
    genai.configure(api_key=GEMINI_API_KEY)
    print("‚úÖ Gemini AI configured successfully")

# Initialize startup
print("üöÄ COMPLETE E-con News Backend v2.024.11:")
print(f"Gemini AI: {'‚úÖ' if GEMINI_API_KEY else '‚ùå'}")
print(f"Content Extraction: {'‚úÖ' if TRAFILATURA_AVAILABLE else '‚ùå'}")
print(f"Terminal Commands: ‚úÖ ALL METHODS IMPLEMENTED")
print(f"RSS Feeds: ‚úÖ {sum(len(feeds) for feeds in RSS_FEEDS.values())} sources")
print(f"AI Summary Length: ‚úÖ FIXED (100-200 words)")
print(f"Session Management: ‚úÖ ENHANCED ERROR HANDLING")
print(f"News Loading: ‚úÖ BETTER ERROR RECOVERY")
print("=" * 60)

# Create app instance
app = create_app()

if __name__ == '__main__':
    app.run(
        host='0.0.0.0',
        port=int(os.getenv('PORT', 5000)),
        debug=DEBUG_MODE,
        threaded=True
    )
