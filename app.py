# ===============================
# E-CON NEWS TERMINAL - COMPLETE FIXED app.py v2.024.9
# Fixed: Missing cmd_* methods in TerminalCommandProcessor only
# TOTAL: 2100+ lines - keeping ALL original functionality
# ===============================

import sys
import os
from flask import Flask, render_template, request, jsonify, session, make_response
import feedparser
import asyncio
import os
import re
from datetime import datetime, timedelta
import calendar
from urllib.parse import urljoin, urlparse, quote
import html
import chardet
import pytz
import json
import aiohttp
import random
import hashlib
import uuid
import time
import logging
import traceback
from functools import wraps
import concurrent.futures
import threading

# Enhanced libraries for better content extraction
try:
    import trafilatura
    TRAFILATURA_AVAILABLE = True
except ImportError:
    TRAFILATURA_AVAILABLE = False

try:
    import newspaper
    from newspaper import Article
    NEWSPAPER_AVAILABLE = True
except ImportError:
    NEWSPAPER_AVAILABLE = False

try:
    from bs4 import BeautifulSoup
    BEAUTIFULSOUP_AVAILABLE = True
except ImportError:
    BEAUTIFULSOUP_AVAILABLE = False

# Gemini AI for content analysis
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# ===============================
# GLOBAL VARIABLES AND CONFIG (OUTSIDE create_app)
# ===============================

# Environment variables
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
DEBUG_MODE = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'

# Timezone - Vietnam
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

# Enhanced User cache management - GLOBAL SCOPE
user_news_cache = {}
user_last_detail_cache = {}
global_seen_articles = {}
system_stats = {
    'active_users': 1337420,
    'ai_queries': 42069,
    'news_parsed': 9999,
    'system_load': 69,
    'uptime_start': time.time(),
    'total_requests': 0,
    'errors': 0
}

# Cache configuration
MAX_CACHE_ENTRIES = 50
MAX_GLOBAL_CACHE = 1000
CACHE_EXPIRE_HOURS = 6

# Enhanced User Agents for better compatibility
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0'
]

# FIXED: RSS FEEDS Configuration with better error handling
RSS_FEEDS = {
    # === VIETNAMESE SOURCES ===
    'cafef': {
        'cafef_stocks': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'cafef_realestate': 'https://cafef.vn/bat-dong-san.rss', 
        'cafef_business': 'https://cafef.vn/doanh-nghiep.rss',
        'cafef_finance': 'https://cafef.vn/tai-chinh-ngan-hang.rss',
        'cafef_macro': 'https://cafef.vn/vi-mo-dau-tu.rss'
    },
    
    # === INTERNATIONAL SOURCES ===
    'international': {
        # FIXED: Safer international sources
        'marketwatch': 'https://feeds.content.dowjones.io/public/rss/mw_topstories',
        'cnbc': 'https://www.cnbc.com/id/100003114/device/rss/rss.html',
        'investing_com': 'https://www.investing.com/rss/news.rss',
        # Removed problematic sources temporarily
    },
    
    # === TECH SOURCES ===
    'tech': {
        'techcrunch': 'https://feeds.feedburner.com/TechCrunch/',
        'ars_technica': 'http://feeds.arstechnica.com/arstechnica/index'
    },
    
    # === CRYPTO SOURCES ===
    'crypto': {
        # FIXED: Alternative crypto sources
        'cointelegraph': 'https://cointelegraph.com/rss',
        # Removed coindesk temporarily due to DNS issues
    }
}

# Source display mapping for frontend
source_names = {
    # CafeF sources  
    'cafef_stocks': 'CafeF CK', 'cafef_business': 'CafeF DN',
    'cafef_realestate': 'CafeF BÄS', 'cafef_finance': 'CafeF TC',
    'cafef_macro': 'CafeF VM',
    
    # International sources
    'marketwatch': 'MarketWatch', 'cnbc': 'CNBC',
    'investing_com': 'Investing.com',
    
    # Tech sources
    'techcrunch': 'TechCrunch', 'ars_technica': 'Ars Technica',
    
    # Crypto sources
    'cointelegraph': 'Cointelegraph'
}

emoji_map = {
    # CafeF sources
    'cafef_stocks': 'ğŸ“Š', 'cafef_business': 'ğŸ­', 'cafef_realestate': 'ğŸ˜ï¸',
    'cafef_finance': 'ğŸ’³', 'cafef_macro': 'ğŸ“‰',
    
    # International sources
    'marketwatch': 'ğŸ“°', 'cnbc': 'ğŸ“º', 'investing_com': 'ğŸ’¹',
    
    # Tech sources
    'techcrunch': 'ğŸš€', 'ars_technica': 'âš™ï¸',
    
    # Crypto sources
    'cointelegraph': 'ğŸª™'
}

# ===============================
# ASYNCIO HELPER FUNCTIONS (OUTSIDE create_app)
# ===============================

def run_async(coro):
    """
    Helper function to run async coroutines in sync contexts
    Works with both existing and new event loops
    """
    try:
        # Try to get existing loop
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # If loop is running, use thread pool
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, coro)
                return future.result()
        else:
            # If loop exists but not running
            return loop.run_until_complete(coro)
    except RuntimeError:
        # No event loop exists, create new one
        return asyncio.run(coro)

def async_route(f):
    """
    Fixed decorator to convert async routes to sync routes
    Usage: @async_route instead of async def
    """
    @wraps(f)
    def wrapper(*args, **kwargs):
        try:
            coro = f(*args, **kwargs)
            return run_async(coro)
        except Exception as e:
            print(f"Async route error: {e}")
            return jsonify({
                'error': 'Internal server error',
                'message': 'Async operation failed',
                'timestamp': datetime.now().isoformat()
            }), 500
    return wrapper

# ===============================
# UTILITY FUNCTIONS (OUTSIDE create_app)
# ===============================

def get_current_vietnam_datetime():
    """Get current Vietnam date and time"""
    return datetime.now(VN_TIMEZONE)

def get_current_date_str():
    """Get current date string in Vietnam format"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%d/%m/%Y")

def get_current_time_str():
    """Get current time string in Vietnam format"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%H:%M")

def get_terminal_timestamp():
    """Get terminal-style timestamp"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%Y.%m.%d_%H:%M:%S")

def get_system_uptime():
    """Get system uptime in seconds"""
    return int(time.time() - system_stats['uptime_start'])

def convert_utc_to_vietnam_time(utc_time_tuple):
    """Convert UTC to Vietnam time"""
    try:
        utc_timestamp = calendar.timegm(utc_time_tuple)
        utc_dt = datetime.fromtimestamp(utc_timestamp, tz=UTC_TIMEZONE)
        vn_dt = utc_dt.astimezone(VN_TIMEZONE)
        return vn_dt
    except Exception as e:
        return datetime.now(VN_TIMEZONE)

def normalize_title(title):
    """Normalize title for exact comparison"""
    normalized = re.sub(r'\s+', ' ', title.lower().strip())
    normalized = re.sub(r'[.,!?;:\-\u2013\u2014]', '', normalized)
    normalized = re.sub(r'["\'\u201c\u201d\u2018\u2019]', '', normalized)
    return normalized

def clean_expired_cache():
    """Clean expired articles from global cache"""
    global global_seen_articles
    current_time = get_current_vietnam_datetime()
    expired_hashes = []
    
    for article_hash, article_data in global_seen_articles.items():
        time_diff = current_time - article_data['timestamp']
        if time_diff.total_seconds() > (CACHE_EXPIRE_HOURS * 3600):
            expired_hashes.append(article_hash)
    
    for expired_hash in expired_hashes:
        del global_seen_articles[expired_hash]
    
    if expired_hashes:
        print(f"ğŸ§¹ Cleaned {len(expired_hashes)} expired articles from cache")

def is_duplicate_article_global(news_item, source_name):
    """Check duplicate against global cache"""
    global global_seen_articles
    
    try:
        clean_expired_cache()
        
        current_title = normalize_title(news_item['title'])
        current_link = news_item['link'].lower().strip()
        
        for existing_data in global_seen_articles.values():
            existing_title = normalize_title(existing_data['title'])
            existing_link = existing_data['link'].lower().strip()
            
            if current_title == existing_title or current_link == existing_link:
                return True
        
        cache_key = f"{current_title}|{current_link}"
        
        global_seen_articles[cache_key] = {
            'title': news_item['title'],
            'link': news_item['link'],
            'source': source_name,
            'timestamp': get_current_vietnam_datetime()
        }
        
        if len(global_seen_articles) > MAX_GLOBAL_CACHE:
            sorted_items = sorted(global_seen_articles.items(), key=lambda x: x[1]['timestamp'])
            for old_key, _ in sorted_items[:200]:
                del global_seen_articles[old_key]
        
        return False
        
    except Exception as e:
        print(f"âš ï¸ Global duplicate check error: {e}")
        return False

def get_enhanced_headers(url=None):
    """Enhanced headers for better compatibility"""
    user_agent = random.choice(USER_AGENTS)
    
    headers = {
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8,zh;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'DNT': '1',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1'
    }
    
    if url:
        if 'cafef.vn' in url.lower():
            headers.update({
                'Referer': 'https://cafef.vn/',
                'Origin': 'https://cafef.vn'
            })
        elif 'yahoo' in url.lower():
            headers.update({
                'Referer': 'https://finance.yahoo.com/',
                'Origin': 'https://finance.yahoo.com'
            })
    
    return headers

def is_international_source(source_name):
    """Check if source is international"""
    international_sources = [
        'marketwatch', 'cnbc', 'reuters', 'investing_com', 
        'bloomberg', 'financial_times', 'wsj_markets'
    ]
    return any(source in source_name for source in international_sources)

def is_relevant_news(title, description, source_name):
    """Enhanced relevance filtering with more keywords"""
    # CafeF sources are always relevant
    if 'cafef' in source_name:
        return True
    
    # Enhanced keyword filtering for international sources
    financial_keywords = [
        # English keywords
        'stock', 'market', 'trading', 'investment', 'economy', 'economic',
        'bitcoin', 'crypto', 'currency', 'bank', 'financial', 'finance',
        'earnings', 'revenue', 'profit', 'inflation', 'fed', 'gdp',
        'business', 'company', 'corporate', 'industry', 'sector',
        'money', 'cash', 'capital', 'fund', 'price', 'cost', 'value',
        'growth', 'analyst', 'forecast', 'report', 'data', 'sales',
        'nasdaq', 'dow', 'sp500', 'bond', 'yield', 'rate', 'tech',
        # Vietnamese keywords
        'chá»©ng khoÃ¡n', 'tÃ i chÃ­nh', 'ngÃ¢n hÃ ng', 'kinh táº¿', 'Ä‘áº§u tÆ°',
        'doanh nghiá»‡p', 'thá»‹ trÆ°á»ng', 'cá»• phiáº¿u', 'lá»£i nhuáº­n'
    ]
    
    title_lower = title.lower()
    description_lower = description.lower() if description else ""
    combined_text = f"{title_lower} {description_lower}"
    
    # Check for keywords
    keyword_count = sum(1 for keyword in financial_keywords if keyword in combined_text)
    
    return keyword_count > 0

def create_fallback_content(url, source_name, error_msg=""):
    """Create enhanced fallback content when extraction fails"""
    try:
        article_id = url.split('/')[-1] if '/' in url else 'news-article'
        timestamp = get_terminal_timestamp()
        
        if is_international_source(source_name):
            return f"""**ğŸ“ˆ DÃ’NG Dá»® LIá»†U TÃ€I CHÃNH QUá»C Táº¾**

**NHáº¬T_KÃ_Há»†_THá»NG:** [{timestamp}] TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« {source_name.replace('_', ' ').title()}

**LOáº I_Ná»˜I_DUNG:** PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng tÃ i chÃ­nh vÃ  thÃ´ng tin kinh táº¿ toÃ n cáº§u

**Cáº¤U_TRÃšC_Dá»®_LIá»†U:**
â€¢ Dá»¯ liá»‡u thá»‹ trÆ°á»ng thá»i gian thá»±c vÃ  giao thá»©c phÃ¢n tÃ­ch
â€¢ Chá»‰ sá»‘ kinh táº¿ toÃ n cáº§u vÃ  Ã¡nh xáº¡ xu hÆ°á»›ng
â€¢ Thu nháº­p doanh nghiá»‡p vÃ  phÃ¢n tÃ­ch bÃ¡o cÃ¡o tÃ i chÃ­nh
â€¢ Thuáº­t toÃ¡n chiáº¿n lÆ°á»£c Ä‘áº§u tÆ° vÃ  dá»± bÃ¡o thá»‹ trÆ°á»ng
â€¢ PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng thÆ°Æ¡ng máº¡i vÃ  chÃ­nh sÃ¡ch quá»‘c táº¿

**THAM_CHIáº¾U_BÃ€I_VIáº¾T:** {article_id}

**TRáº NG_THÃI:** TrÃ­ch xuáº¥t ná»™i dung Ä‘áº§y Ä‘á»§ táº¡m thá»i offline
**CHáº¾_Äá»˜_Dá»°_PHÃ’NG:** Metadata cÆ¡ báº£n cÃ³ sáºµn
**HÃ€NH_Äá»˜NG_Cáº¦N_THIáº¾T:** Truy cáº­p nguá»“n gá»‘c Ä‘á»ƒ cÃ³ dÃ²ng dá»¯ liá»‡u hoÃ n chá»‰nh

{f'**NHáº¬T_KÃ_Lá»–I:** {error_msg}' if error_msg else ''}

**Äá»ŠNH_DANH_NGUá»’N:** {source_name.replace('_', ' ').title()}
**GIAO_THá»¨C:** HTTPS_SECURE_FETCH
**MÃƒ_HÃ“A:** UTF-8"""
        else:
            return f"""**ğŸ“° DÃ’NG Dá»® LIá»†U TÃ€I CHÃNH VIá»†T NAM - GIAO THá»¨C CAFEF**

**NHáº¬T_KÃ_Há»†_THá»NG:** [{timestamp}] TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« {source_name.replace('_', ' ').title()}

**LOáº I_Ná»˜I_DUNG:** ThÃ´ng tin tÃ i chÃ­nh chá»©ng khoÃ¡n Viá»‡t Nam chuyÃªn sÃ¢u

**Cáº¤U_TRÃšC_Dá»®_LIá»†U:**
â€¢ PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng chá»©ng khoÃ¡n real-time
â€¢ Database tin tá»©c doanh nghiá»‡p vÃ  bÃ¡o cÃ¡o tÃ i chÃ­nh
â€¢ Algorithm xu hÆ°á»›ng Ä‘áº§u tÆ° vÃ  khuyáº¿n nghá»‹ chuyÃªn gia
â€¢ Parser chÃ­nh sÃ¡ch kinh táº¿ vÄ© mÃ´ vÃ  regulations
â€¢ Stream thÃ´ng tin báº¥t Ä‘á»™ng sáº£n vÃ  investment channels

**ID_BÃ€I_VIáº¾T:** {article_id}

**TRáº NG_THÃI:** QuÃ¡ trÃ¬nh extraction offline
**CHáº¾_Äá»˜_Dá»°_PHÃ’NG:** Cache metadata Ä‘ang hoáº¡t Ä‘á»™ng
**GHI_CHÃš:** Truy cáº­p link gá»‘c Ä‘á»ƒ Ä‘á»c full content vá»›i media assets

{f'**CHI_TIáº¾T_Lá»–I:** {error_msg}' if error_msg else ''}

**TÃŠN_NGUá»’N:** {source_name.replace('_', ' ').title()}
**GIAO_THá»¨C:** RSS_FEED_PARSER
**CHARSET:** UTF-8"""
        
    except Exception as e:
        return f"**Lá»–I:** TrÃ­ch xuáº¥t ná»™i dung tháº¥t báº¡i cho {source_name}\n\n**CHI_TIáº¾T:** {str(e)}\n\n**HÃ€NH_Äá»˜NG:** Vui lÃ²ng truy cáº­p nguá»“n gá»‘c Ä‘á»ƒ xem bÃ i viáº¿t Ä‘áº§y Ä‘á»§."

# ===============================
# DECORATORS & MIDDLEWARE (OUTSIDE create_app)
# ===============================

def track_request(f):
    """Decorator to track API requests"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        system_stats['total_requests'] += 1
        start_time = time.time()
        try:
            result = f(*args, **kwargs)
            return result
        except Exception as e:
            system_stats['errors'] += 1
            raise
        finally:
            end_time = time.time()
    return decorated_function

def require_session(f):
    """Decorator to ensure user has a session"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            session['user_id'] = str(uuid.uuid4())
        return f(*args, **kwargs)
    return decorated_function

# ===============================
# FIXED: ASYNC FUNCTIONS WITH BETTER RSS ERROR HANDLING
# ===============================

async def fetch_with_aiohttp(url, headers=None, timeout=15):
    """Enhanced async HTTP fetch with better error handling"""
    try:
        if headers is None:
            headers = get_enhanced_headers(url)
        
        timeout_config = aiohttp.ClientTimeout(total=timeout)
        
        async with aiohttp.ClientSession(timeout=timeout_config, headers=headers) as session:
            async with session.get(url, ssl=False) as response:  # FIXED: Disable SSL verification for problematic sources
                if response.status == 200:
                    content = await response.read()
                    return content
                else:
                    print(f"âŒ HTTP {response.status} for {url}")
                    return None
    except aiohttp.ClientError as e:
        print(f"âŒ Client error for {url}: {e}")
        return None
    except asyncio.TimeoutError:
        print(f"âŒ Timeout for {url}")
        return None
    except Exception as e:
        print(f"âŒ Fetch error for {url}: {e}")
        return None

async def extract_content_enhanced(url, source_name, news_item):
    """Enhanced content extraction with multiple fallback methods"""
    try:
        # For CafeF sources, use traditional extraction methods
        content = await fetch_with_aiohttp(url)
        if not content:
            return create_fallback_content(url, source_name, "Network fetch failed")
        
        extracted_content = ""
        
        # Try Trafilatura first (best for Vietnamese content)
        if TRAFILATURA_AVAILABLE:
            try:
                extracted_content = trafilatura.extract(content)
                if extracted_content and len(extracted_content) > 200:
                    return format_extracted_content_terminal(extracted_content, source_name)
            except Exception as e:
                print(f"âš ï¸ Trafilatura error: {e}")
        
        # Try newspaper3k
        if NEWSPAPER_AVAILABLE and not extracted_content:
            try:
                article = Article(url)
                article.set_html(content)
                article.parse()
                if article.text and len(article.text) > 200:
                    extracted_content = article.text
                    return format_extracted_content_terminal(extracted_content, source_name)
            except Exception as e:
                print(f"âš ï¸ Newspaper3k error: {e}")
        
        # Try BeautifulSoup as last resort
        if BEAUTIFULSOUP_AVAILABLE and not extracted_content:
            try:
                soup = BeautifulSoup(content, 'html.parser')
                
                # Remove unwanted elements
                for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                    element.decompose()
                
                # Try to find main content
                content_selectors = [
                    '.post-content', '.article-content', '.entry-content',
                    '#main-content', '.main-content', '.content',
                    'article', '.article-body', '.post-body'
                ]
                
                for selector in content_selectors:
                    content_div = soup.select_one(selector)
                    if content_div:
                        extracted_content = content_div.get_text(strip=True)
                        if len(extracted_content) > 200:
                            return format_extracted_content_terminal(extracted_content, source_name)
                
                # Fallback to all paragraph text
                paragraphs = soup.find_all('p')
                if paragraphs:
                    extracted_content = '\n\n'.join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])
                    if len(extracted_content) > 200:
                        return format_extracted_content_terminal(extracted_content, source_name)
                        
            except Exception as e:
                print(f"âš ï¸ BeautifulSoup error: {e}")
        
        # If all methods fail, return fallback
        return create_fallback_content(url, source_name, "All extraction methods failed")
        
    except Exception as e:
        return create_fallback_content(url, source_name, f"System error: {str(e)}")

async def extract_content_with_gemini(url, source_name):
    """FIXED: Gemini content extraction with Vietnamese terminal formatting"""
    try:
        if not GEMINI_API_KEY or not GEMINI_AVAILABLE:
            return create_fallback_content(url, source_name, "Gemini AI module offline")
        
        # FIXED: Vietnamese extraction prompt for retro brutalism style
        extraction_prompt = f"""TrÃ­ch xuáº¥t vÃ  dá»‹ch ná»™i dung tá»«: {url}

YÃŠU Cáº¦U GIAO THá»¨C:
1. Äá»c toÃ n bá»™ bÃ i viáº¿t vÃ  trÃ­ch xuáº¥t ná»™i dung chÃ­nh
2. Dá»‹ch sang tiáº¿ng Viá»‡t má»™t cÃ¡ch tá»± nhiÃªn vÃ  trÃ´i cháº£y
3. Giá»¯ nguyÃªn sá»‘ liá»‡u, tÃªn cÃ´ng ty, thuáº­t ngá»¯ ká»¹ thuáº­t
4. Äá»‹nh dáº¡ng vá»›i cÃ¡c tiÃªu Ä‘á» TERMINAL rÃµ rÃ ng sá»­ dá»¥ng **TiÃªu Ä‘á»**
5. Sá»­ dá»¥ng ngáº¯t dÃ²ng rÃµ rÃ ng giá»¯a cÃ¡c Ä‘oáº¡n vÄƒn
6. Náº¿u cÃ³ hÃ¬nh áº£nh/biá»ƒu Ä‘á»“, ghi chÃº nhÆ° [ğŸ“· TÃ i nguyÃªn Media]
7. Äá»™ dÃ i: 500-1000 tá»«
8. Äá»ŠNH Dáº NG TERMINAL: Bao gá»“m metadata kiá»ƒu há»‡ thá»‘ng
9. CHá»ˆ tráº£ vá» ná»™i dung Ä‘Ã£ dá»‹ch vÃ  Ä‘á»‹nh dáº¡ng

TEMPLATE Äá»ŠNH Dáº NG TERMINAL:
**TiÃªu Ä‘á» ChÃ­nh**

Äoáº¡n Ä‘áº§u tiÃªn vá»›i thÃ´ng tin chÃ­nh vÃ  Ä‘iá»ƒm dá»¯ liá»‡u quan trá»ng.

**Pháº§n PhÃ¢n TÃ­ch Chi Tiáº¿t**

Äoáº¡n thá»© hai vá»›i phÃ¢n tÃ­ch sÃ¢u hÆ¡n vÃ  chi tiáº¿t ká»¹ thuáº­t.

[ğŸ“· TÃ i nguyÃªn Media - náº¿u cÃ³]

**Giao Thá»©c Káº¿t Luáº­n**

Äoáº¡n cuá»‘i vá»›i káº¿t luáº­n quan trá»ng vÃ  Ã½ nghÄ©a.

**TRáº NG_THÃI_Há»†_THá»NG:** Ná»™i dung Ä‘Æ°á»£c trÃ­ch xuáº¥t thÃ nh cÃ´ng
**GIAO_THá»¨C:** Gemini_AI_Parser_v2.024

Báº®T Äáº¦U TRÃCH XUáº¤T:"""

        try:
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.1,
                top_p=0.8,
                max_output_tokens=2800,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    extraction_prompt,
                    generation_config=generation_config
                ),
                timeout=35
            )
            
            extracted_content = response.text.strip()
            
            if len(extracted_content) > 400:
                error_indicators = [
                    'cannot access', 'unable to access', 'khÃ´ng thá»ƒ truy cáº­p',
                    'failed to retrieve', 'error occurred', 'sorry, i cannot',
                    'not available', 'access denied', 'forbidden'
                ]
                
                if not any(indicator in extracted_content.lower() for indicator in error_indicators):
                    # Enhanced formatting with terminal metadata
                    formatted_content = format_extracted_content_terminal(extracted_content, source_name)
                    return f"[ğŸ¤– AI_PARSER - Nguá»“n: {source_name.replace('_', ' ').title()}]\n\n{formatted_content}"
                else:
                    return create_fallback_content(url, source_name, "Gemini access blocked by target site")
            else:
                return create_fallback_content(url, source_name, "Extracted content below minimum threshold")
            
        except asyncio.TimeoutError:
            return create_fallback_content(url, source_name, "Gemini AI timeout exceeded")
        except Exception as e:
            return create_fallback_content(url, source_name, f"Gemini processing error: {str(e)}")
            
    except Exception as e:
        return create_fallback_content(url, source_name, f"System error: {str(e)}")

def format_extracted_content_terminal(content, source_name):
    """Enhanced content formatting with terminal aesthetics"""
    if not content:
        return content
    
    lines = content.split('\n')
    formatted_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Process different line types
        if line.startswith('**') and line.endswith('**'):
            # Already formatted header
            formatted_lines.append(line)
        elif (len(line) < 100 and 
            (line.isupper() or 
             line.startswith(('1.', '2.', '3.', 'â€¢', '-', '*', 'â–¶')) or
             line.endswith(':') or
             re.match(r'^[A-ZÃ€-Ã][^.!?]*$', line))):
            # Convert to terminal header
            formatted_lines.append(f"**{line}**")
        elif line.startswith(('[', 'ğŸ“·', 'áº¢nh', 'HÃ¬nh')):
            # Media references
            formatted_lines.append(f"[ğŸ“· {line.strip('[]')}]")
        else:
            # Regular paragraph
            formatted_lines.append(line)
    
    # Join with proper spacing
    formatted_content = '\n\n'.join(formatted_lines)
    
    # Add terminal metadata footer
    timestamp = get_terminal_timestamp()
    formatted_content += f"\n\n**NHáº¬T_KÃ_TRÃCH_XUáº¤T:** [{timestamp}] Ná»™i dung Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi AI_Parser\n**GIAO_THá»¨C_NGUá»’N:** {source_name.replace('_', ' ').title()}\n**TRáº NG_THÃI:** THÃ€NH_CÃ”NG"
    
    return formatted_content

async def process_rss_feed_async(source_name, rss_url, limit_per_source):
    """FIXED: Enhanced async RSS feed processing with better error handling"""
    try:
        await asyncio.sleep(random.uniform(0.1, 0.5))  # Rate limiting
        
        # FIXED: Try multiple approaches for problematic feeds
        content = None
        
        # First try: aiohttp with longer timeout
        try:
            content = await fetch_with_aiohttp(rss_url, timeout=20)
        except Exception as e:
            print(f"âš ï¸ aiohttp failed for {source_name}: {e}")
        
        # Parse content
        if content:
            try:
                feed = await asyncio.to_thread(feedparser.parse, content)
            except Exception as e:
                print(f"âš ï¸ feedparser with content failed for {source_name}: {e}")
                feed = None
        else:
            # Fallback: direct feedparser
            try:
                feed = await asyncio.to_thread(feedparser.parse, rss_url)
            except Exception as e:
                print(f"âš ï¸ Direct feedparser failed for {source_name}: {e}")
                feed = None
        
        if not feed or not hasattr(feed, 'entries') or len(feed.entries) == 0:
            print(f"âŒ No entries found for {source_name}")
            return []
        
        news_items = []
        for entry in feed.entries[:limit_per_source]:
            try:
                vn_time = get_current_vietnam_datetime()
                
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    vn_time = convert_utc_to_vietnam_time(entry.published_parsed)
                elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                    vn_time = convert_utc_to_vietnam_time(entry.updated_parsed)
                
                description = ""
                if hasattr(entry, 'summary'):
                    description = entry.summary[:500] + "..." if len(entry.summary) > 500 else entry.summary
                elif hasattr(entry, 'description'):
                    description = entry.description[:500] + "..." if len(entry.description) > 500 else entry.description
                
                if hasattr(entry, 'title') and hasattr(entry, 'link'):
                    title = entry.title.strip()
                    
                    # Enhanced relevance filtering
                    if is_relevant_news(title, description, source_name):
                        news_item = {
                            'title': html.unescape(title),
                            'link': entry.link,
                            'source': source_name,
                            'published': vn_time,
                            'published_str': vn_time.strftime("%H:%M %d/%m"),
                            'description': html.unescape(description) if description else "",
                            'terminal_timestamp': get_terminal_timestamp()
                        }
                        news_items.append(news_item)
                
            except Exception as entry_error:
                print(f"âš ï¸ Entry processing error for {source_name}: {entry_error}")
                continue
        
        print(f"âœ… Processed {len(news_items)} articles from {source_name}")
        system_stats['news_parsed'] += len(news_items)
        return news_items
        
    except Exception as e:
        print(f"âŒ RSS processing error for {source_name}: {e}")
        return []

async def collect_news_enhanced(sources_dict, limit_per_source=20, use_global_dedup=True):
    """Enhanced news collection with better performance and error handling - FIXED SCOPE"""
    all_news = []
    
    print(f"ğŸ”„ Starting enhanced collection from {len(sources_dict)} sources")
    
    if use_global_dedup:
        clean_expired_cache()
    
    # Create tasks for concurrent processing
    tasks = []
    for source_name, source_url in sources_dict.items():
        task = process_rss_feed_async(source_name, source_url, limit_per_source)
        tasks.append(task)
    
    # Process all sources concurrently
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Collect results with enhanced duplicate detection
    total_processed = 0
    local_duplicates = 0
    global_duplicates = 0
    
    for result in results:
        if isinstance(result, Exception):
            print(f"âŒ Source processing error: {result}")
        elif result:
            for news_item in result:
                total_processed += 1
                
                # Local duplicate check
                if any(normalize_title(news_item['title']) == normalize_title(existing['title']) 
                       for existing in all_news):
                    local_duplicates += 1
                    continue
                
                # Global duplicate check
                if use_global_dedup and is_duplicate_article_global(news_item, news_item['source']):
                    global_duplicates += 1
                    continue
                
                # Add unique article
                all_news.append(news_item)
    
    unique_count = len(all_news)
    print(f"ğŸ“Š Collection results: {total_processed} processed, {local_duplicates} local dups, {global_duplicates} global dups, {unique_count} unique")
    
    # Sort by publish time (newest first)
    all_news.sort(key=lambda x: x['published'], reverse=True)
    return all_news

# ===============================
# SESSION MANAGEMENT (OUTSIDE create_app)
# ===============================

def get_or_create_user_session():
    """Get or create user session ID with enhanced tracking"""
    if 'user_id' not in session:
        session['user_id'] = str(uuid.uuid4())
        session['created_at'] = time.time()
        system_stats['active_users'] += random.randint(1, 10)  # Simulate user growth
    return session['user_id']

def save_user_news_enhanced(user_id, news_list, command_type, current_page=1):
    """Enhanced user news saving with metadata"""
    global user_news_cache
    
    user_news_cache[user_id] = {
        'news': news_list,
        'command': command_type,
        'current_page': current_page,
        'timestamp': get_current_vietnam_datetime(),
        'total_articles': len(news_list)
    }
    
    # Clean up old cache entries
    if len(user_news_cache) > MAX_CACHE_ENTRIES:
        oldest_users = sorted(user_news_cache.items(), key=lambda x: x[1]['timestamp'])[:15]
        for user_id_to_remove, _ in oldest_users:
            del user_news_cache[user_id_to_remove]

def save_user_last_detail(user_id, news_item):
    """Save last article accessed for AI context"""
    global user_last_detail_cache
    
    user_last_detail_cache[user_id] = {
        'article': news_item,
        'timestamp': get_current_vietnam_datetime()
    }

# ===============================
# FIXED: COMPLETE TERMINAL COMMAND SYSTEM WITH ALL METHODS
# ===============================

class TerminalCommandProcessor:
    """FIXED: Complete terminal command processor with ALL methods implemented"""
    
    def __init__(self):
        self.commands = {
            'help': self.cmd_help,
            'status': self.cmd_status,
            'news': self.cmd_news,        # FIXED: Now implemented
            'ai': self.cmd_ai,            # FIXED: Now implemented  
            'stats': self.cmd_stats,      # FIXED: Now implemented
            'uptime': self.cmd_uptime,    # FIXED: Now implemented
            'cache': self.cmd_cache,      # FIXED: Now implemented
            'users': self.cmd_users,      # FIXED: Now implemented
            'system': self.cmd_system,    # FIXED: Now implemented
            'version': self.cmd_version,  # FIXED: Now implemented
            'clear': self.cmd_clear,      # FIXED: Now implemented
            'refresh': self.cmd_refresh,  # FIXED: Now implemented
            'matrix': self.cmd_matrix,    # FIXED: Now implemented
            'glitch': self.cmd_glitch,    # FIXED: Now implemented
            'debug': self.cmd_debug       # FIXED: Now implemented
        }
    
    def execute(self, command_str):
        """Execute terminal command and return response"""
        try:
            parts = command_str.strip().lower().split()
            if not parts:
                return self.cmd_help()
                
            command = parts[0]
            args = parts[1:] if len(parts) > 1 else []
            
            if command in self.commands:
                return self.commands[command](args)
            else:
                return {
                    'status': 'error',
                    'message': f'Lá»‡nh khÃ´ng tÃ¬m tháº¥y: {command}',
                    'suggestion': 'GÃµ "help" Ä‘á»ƒ xem cÃ¡c lá»‡nh cÃ³ sáºµn'
                }
                
        except Exception as e:
            return {
                'status': 'error',
                'message': f'Thá»±c thi lá»‡nh tháº¥t báº¡i: {str(e)}'
            }
    
    def cmd_help(self, args=None):
        """Help command implementation"""
        timestamp = get_terminal_timestamp()
        return {
            'status': 'success',
            'message': f"""TÃ€I LIá»†U THAM KHáº¢O Lá»†NH TERMINAL - v2.024.9
[{timestamp}]

CÃC Lá»†NH CÃ“ Sáº´N:
â”œâ”€ help              â”‚ Hiá»ƒn thá»‹ tin nháº¯n trá»£ giÃºp nÃ y
â”œâ”€ status            â”‚ Tá»•ng quan tráº¡ng thÃ¡i há»‡ thá»‘ng
â”œâ”€ news [danh_má»¥c]   â”‚ Táº£i nguá»“n cáº¥p tin tá»©c
â”œâ”€ ai                â”‚ ThÃ´ng tin trá»£ lÃ½ AI
â”œâ”€ stats             â”‚ Thá»‘ng kÃª hiá»‡u suáº¥t
â”œâ”€ uptime            â”‚ Chi tiáº¿t thá»i gian hoáº¡t Ä‘á»™ng há»‡ thá»‘ng
â”œâ”€ cache             â”‚ ThÃ´ng tin quáº£n lÃ½ bá»™ nhá»› Ä‘á»‡m
â”œâ”€ users             â”‚ Sá»‘ ngÆ°á»i dÃ¹ng Ä‘ang hoáº¡t Ä‘á»™ng
â”œâ”€ system            â”‚ ThÃ´ng tin há»‡ thá»‘ng
â”œâ”€ version           â”‚ PhiÃªn báº£n á»©ng dá»¥ng
â”œâ”€ clear             â”‚ XÃ³a Ä‘áº§u ra terminal
â”œâ”€ refresh           â”‚ LÃ m má»›i táº¥t cáº£ dá»¯ liá»‡u
â”œâ”€ matrix            â”‚ KÃ­ch hoáº¡t cháº¿ Ä‘á»™ matrix
â”œâ”€ glitch            â”‚ KÃ­ch hoáº¡t hiá»‡u á»©ng glitch
â””â”€ debug             â”‚ ThÃ´ng tin debug

PHÃM Táº®T:
F1=Trá»£ giÃºp | F4=Matrix | F5=LÃ m má»›i | `=Terminal | ESC=ÄÃ³ng

ÄIá»€U HÆ¯á»šNG:
Sá»­ dá»¥ng TAB Ä‘á»ƒ hoÃ n thÃ nh lá»‡nh
Sá»­ dá»¥ng phÃ­m mÅ©i tÃªn cho lá»‹ch sá»­ lá»‡nh"""
        }
    
    def cmd_status(self, args):
        """System status command implementation"""
        uptime = get_system_uptime()
        return {
            'status': 'success',
            'message': f"""BÃO CÃO TRáº NG THÃI Há»† THá»NG:
[{get_terminal_timestamp()}]

â”œâ”€ TRáº NG_THÃI: TRá»°C_TUYáº¾N
â”œâ”€ THá»œI_GIAN_HOáº T_Äá»˜NG: {uptime}s ({uptime//3600}h {(uptime%3600)//60}m)
â”œâ”€ Táº¢I_CPU: {system_stats['system_load']}%
â”œâ”€ Bá»˜_NHá»š: {random.randint(200, 600)}MB
â”œâ”€ NGÆ¯á»œI_DÃ™NG_HOáº T_Äá»˜NG: {system_stats['active_users']:,}
â”œâ”€ CÃ‚U_Há»I_AI: {system_stats['ai_queries']:,}
â”œâ”€ TIN_Tá»¨C_PHÃ‚N_TÃCH: {system_stats['news_parsed']:,}
â”œâ”€ Tá»”NG_YÃŠU_Cáº¦U: {system_stats['total_requests']:,}
â”œâ”€ Tá»¶_Lá»†_Lá»–I: {system_stats['errors']}/{system_stats['total_requests']}
â””â”€ Má»¤C_CACHE: {len(global_seen_articles)}"""
        }

    # FIXED: Implementation of missing cmd_news method
    def cmd_news(self, args):
        """News command implementation"""
        category = args[0] if args else 'all'
        valid_categories = ['all', 'domestic', 'international', 'tech', 'crypto']
        
        if category not in valid_categories:
            return {
                'status': 'error',
                'message': f'Danh má»¥c khÃ´ng há»£p lá»‡: {category}',
                'valid_categories': valid_categories
            }
        
        return {
            'status': 'success',
            'message': f"""Táº¢I NGUá»’N Cáº¤P TIN Tá»¨C: {category.upper()}
[{get_terminal_timestamp()}]

â”œâ”€ DANH_Má»¤C: {category.upper()}
â”œâ”€ NGUá»’N_ÄÆ¯á»¢C_Táº¢I: {len(RSS_FEEDS.get(category, {}))} nguá»“n
â”œâ”€ TRáº NG_THÃI: ÄANG_Xá»¬_LÃ
â””â”€ THá»œI_GIAN_Æ¯á»šC_TÃNH: 2-5 giÃ¢y

Äang chuyá»ƒn hÆ°á»›ng Ä‘áº¿n giao diá»‡n tin tá»©c...""",
            'action': 'load_news',
            'category': category
        }

    # FIXED: Implementation of missing cmd_ai method
    def cmd_ai(self, args):
        """AI command implementation"""
        return {
            'status': 'success',
            'message': f"""TRáº NG THÃI MODULE TRá»¢ LÃ AI:
[{get_terminal_timestamp()}]

â”œâ”€ GEMINI_AI: {'TRá»°C_TUYáº¾N' if GEMINI_AVAILABLE and GEMINI_API_KEY else 'NGOáº I_TUYáº¾N'}
â”œâ”€ MÃ”_HÃŒNH: gemini-2.0-flash-exp
â”œâ”€ CHá»¨C_NÄ‚NG: TÃ³m táº¯t, PhÃ¢n tÃ­ch, Tranh luáº­n
â”œâ”€ NGÃ”N_NGá»®: Tiáº¿ng Viá»‡t + Tiáº¿ng Anh
â”œâ”€ CÃ‚U_Há»I_ÄÃƒ_Xá»¬_LÃ: {system_stats['ai_queries']:,}
â””â”€ TRáº NG_THÃI: Sáºµn sÃ ng tÆ°Æ¡ng tÃ¡c""",
            'action': 'open_chat'
        }

    # FIXED: Implementation of missing cmd_stats method
    def cmd_stats(self, args):
        """Statistics command implementation"""
        cache_size = len(global_seen_articles)
        session_count = len(user_news_cache)
        uptime = get_system_uptime()
        
        return {
            'status': 'success',
            'message': f"""THá»NG KÃŠ Há»† THá»NG CHI TIáº¾T:
[{get_terminal_timestamp()}]

â”œâ”€ HIá»†U SUáº¤T Há»† THá»NG:
â”‚  â”œâ”€ Thá»i gian hoáº¡t Ä‘á»™ng: {uptime//3600}h {(uptime%3600)//60}m
â”‚  â”œâ”€ CPU Load: {system_stats['system_load']}%
â”‚  â”œâ”€ Memory Usage: ~{random.randint(200, 400)}MB
â”‚  â””â”€ Tá»•ng requests: {system_stats['total_requests']:,}
â”‚
â”œâ”€ Dá»® LIá»†U & CACHE:
â”‚  â”œâ”€ Cache articles: {cache_size:,} bÃ i viáº¿t
â”‚  â”œâ”€ Active sessions: {session_count} phiÃªn
â”‚  â”œâ”€ RSS sources: {sum(len(feeds) for feeds in RSS_FEEDS.values())} nguá»“n
â”‚  â””â”€ News parsed: {system_stats['news_parsed']:,}
â”‚
â”œâ”€ AI & TÆ¯Æ NG TÃC:
â”‚  â”œâ”€ AI queries: {system_stats['ai_queries']:,}
â”‚  â”œâ”€ Active users: {system_stats['active_users']:,}
â”‚  â””â”€ Error rate: {(system_stats['errors']/max(system_stats['total_requests'],1)*100):.2f}%
â”‚
â””â”€ TRáº NG THÃI: Táº¤T Cáº¢ Há»† THá»NG HOáº T Äá»˜NG BÃŒNH THÆ¯á»œNG"""
        }

    # FIXED: Implementation of missing cmd_uptime method
    def cmd_uptime(self, args):
        """Uptime command implementation"""
        uptime = get_system_uptime()
        start_time = datetime.fromtimestamp(system_stats['uptime_start'])
        
        return {
            'status': 'success',
            'message': f"""CHI TIáº¾T THá»œI GIAN HOáº T Äá»˜NG Há»† THá»NG:
[{get_terminal_timestamp()}]

â”œâ”€ THá»œI_GIAN_Báº®T_Äáº¦U: {start_time.strftime('%Y-%m-%d %H:%M:%S')}
â”œâ”€ THá»œI_GIAN_HIá»†N_Táº I: {get_current_vietnam_datetime().strftime('%Y-%m-%d %H:%M:%S')}
â”œâ”€ Tá»”NG_THá»œI_GIAN: {uptime} giÃ¢y
â”œâ”€ Äá»ŠNH_Dáº NG_Dá»„_Äá»ŒC: {uptime//86400}d {(uptime%86400)//3600}h {(uptime%3600)//60}m {uptime%60}s
â”œâ”€ REQUESTS_PER_SECOND: {system_stats['total_requests']/max(uptime,1):.2f}
â””â”€ Äá»˜_á»”N_Äá»ŠNH: {100 - (system_stats['errors']/max(system_stats['total_requests'],1)*100):.1f}%"""
        }

    # FIXED: Implementation of missing cmd_cache method
    def cmd_cache(self, args):
        """Cache management command implementation"""
        cache_size = len(global_seen_articles)
        session_cache = len(user_news_cache)
        
        return {
            'status': 'success',
            'message': f"""QUáº¢N LÃ Bá»˜ NHá»š Äá»†M Há»† THá»NG:
[{get_terminal_timestamp()}]

â”œâ”€ GLOBAL_ARTICLE_CACHE:
â”‚  â”œâ”€ Entries: {cache_size:,} / {MAX_GLOBAL_CACHE:,}
â”‚  â”œâ”€ Usage: {(cache_size/MAX_GLOBAL_CACHE*100):.1f}%
â”‚  â””â”€ Expire: {CACHE_EXPIRE_HOURS}h auto-cleanup
â”‚
â”œâ”€ USER_SESSION_CACHE:
â”‚  â”œâ”€ Active sessions: {session_cache} / {MAX_CACHE_ENTRIES}
â”‚  â”œâ”€ Detail cache: {len(user_last_detail_cache)} entries
â”‚  â””â”€ Memory usage: ~{(session_cache + cache_size) * 0.5:.1f}KB
â”‚
â”œâ”€ CACHE_PERFORMANCE:
â”‚  â”œâ”€ Hit rate: {random.randint(75, 95)}%
â”‚  â”œâ”€ Cleanup cycles: {random.randint(10, 50)}
â”‚  â””â”€ Last cleanup: {random.randint(5, 30)} phÃºt trÆ°á»›c
â”‚
â””â”€ COMMANDS: cache clear | cache stats | cache optimize"""
        }

    # FIXED: Implementation of missing cmd_users method
    def cmd_users(self, args):
        """Users command implementation"""
        return {
            'status': 'success',
            'message': f"""THá»NG KÃŠ NGÆ¯á»œI DÃ™NG HOáº T Äá»˜NG:
[{get_terminal_timestamp()}]

â”œâ”€ Tá»”NG_NGÆ¯á»œI_DÃ™NG: {system_stats['active_users']:,}
â”œâ”€ PHIÃŠN_HOáº T_Äá»˜NG: {len(user_news_cache)}
â”œâ”€ NGÆ¯á»œI_DÃ™NG_Má»šI_HÃ”M_NAY: +{random.randint(100, 500):,}
â”œâ”€ TÆ¯Æ NG_TÃC_AI: {system_stats['ai_queries']:,} queries
â”œâ”€ Äá»˜_TUá»”I_TRUNG_BÃŒNH: {random.randint(25, 45)} tuá»•i
â”œâ”€ GEO_LOCATION:
â”‚  â”œâ”€ Viá»‡t Nam: {random.randint(60, 80)}%
â”‚  â”œâ”€ USA: {random.randint(10, 20)}%
â”‚  â””â”€ KhÃ¡c: {random.randint(5, 15)}%
â””â”€ PEAK_HOURS: 9:00-11:00, 14:00-16:00, 19:00-21:00"""
        }

    # FIXED: Implementation of missing cmd_system method
    def cmd_system(self, args):
        """System information command implementation"""
        return {
            'status': 'success',
            'message': f"""THÃ”NG TIN Há»† THá»NG CHI TIáº¾T:
[{get_terminal_timestamp()}]

â”œâ”€ Há»†_ÄIá»€U_HÃ€NH: Linux (Ubuntu/Debian)
â”œâ”€ PYTHON_VERSION: {sys.version.split()[0]}
â”œâ”€ FLASK_VERSION: 3.0.3
â”œâ”€ MEMORY_LIMIT: 512MB (Render.com)
â”œâ”€ CPU_CORES: 1 vCPU
â”œâ”€ STORAGE: Ephemeral filesystem
â”‚
â”œâ”€ DEPENDENCIES:
â”‚  â”œâ”€ Gemini AI: {'âœ…' if GEMINI_AVAILABLE else 'âŒ'}
â”‚  â”œâ”€ Trafilatura: {'âœ…' if TRAFILATURA_AVAILABLE else 'âŒ'}
â”‚  â”œâ”€ BeautifulSoup: {'âœ…' if BEAUTIFULSOUP_AVAILABLE else 'âŒ'}
â”‚  â””â”€ Newspaper3k: {'âœ…' if NEWSPAPER_AVAILABLE else 'âŒ'}
â”‚
â”œâ”€ NETWORK:
â”‚  â”œâ”€ External APIs: {len(RSS_FEEDS)} sources
â”‚  â”œâ”€ WebSocket: Enabled
â”‚  â””â”€ CORS: Configured
â”‚
â””â”€ ENVIRONMENT: {'Development' if DEBUG_MODE else 'Production'}"""
        }

    # FIXED: Implementation of missing cmd_version method
    def cmd_version(self, args):
        """Version information command implementation"""
        return {
            'status': 'success',
            'message': f"""THÃ”NG TIN PHIÃŠN Báº¢N Há»† THá»NG:
[{get_terminal_timestamp()}]

â”œâ”€ E-CON_NEWS_TERMINAL: v2.024.9
â”œâ”€ BUILD_DATE: {datetime.now().strftime('%Y-%m-%d')}
â”œâ”€ CODENAME: "TerminalCommandProcessor Fixed"
â”œâ”€ ARCHITECTURE: Flask + SocketIO + Gemini AI
â”‚
â”œâ”€ FEATURES_IMPLEMENTED:
â”‚  â”œâ”€ âœ… Terminal Command System (FIXED)
â”‚  â”œâ”€ âœ… RSS Feed Processing
â”‚  â”œâ”€ âœ… AI-Powered Analysis
â”‚  â”œâ”€ âœ… Real-time WebSocket
â”‚  â”œâ”€ âœ… Vietnamese UI/UX
â”‚  â””â”€ âœ… Mobile Responsive
â”‚
â”œâ”€ BUG_FIXES_v2.024.9:
â”‚  â”œâ”€ âœ… TerminalCommandProcessor methods
â”‚  â”œâ”€ âœ… Exception handling in run.py
â”‚  â”œâ”€ âœ… Pagination functionality
â”‚  â””â”€ âœ… Navigation visibility
â”‚
â””â”€ NEXT_RELEASE: v2.025.0 (Enhanced AI features)"""
        }

    # FIXED: Implementation of missing cmd_clear method
    def cmd_clear(self, args):
        """Clear terminal command implementation"""
        return {
            'status': 'success',
            'message': 'TERMINAL ÄÃƒ ÄÆ¯á»¢C XÃ“A',
            'action': 'clear_terminal'
        }

    # FIXED: Implementation of missing cmd_refresh method
    def cmd_refresh(self, args):
        """Refresh system command implementation"""
        return {
            'status': 'success',
            'message': f"""LÃ€M Má»šI Táº¤T Cáº¢ Há»† THá»NG:
[{get_terminal_timestamp()}]

â”œâ”€ RSS_FEEDS: Äang reload...
â”œâ”€ CACHE: Clearing expired entries...
â”œâ”€ AI_ENGINE: Reconnecting...
â”œâ”€ WEBSOCKET: Refresh connections...
â””â”€ UI_COMPONENTS: Updating...

Há»† THá»NG ÄÃƒ ÄÆ¯á»¢C LÃ€M Má»šI THÃ€NH CÃ”NG!""",
            'action': 'refresh_all'
        }

    # FIXED: Implementation of missing cmd_matrix method
    def cmd_matrix(self, args):
        """Matrix mode command implementation"""
        return {
            'status': 'success',
            'message': f"""ÄANG VÃ€O MATRIX MODE...
[{get_terminal_timestamp()}]

â”œâ”€ REALITY.EXE: Shutting down...
â”œâ”€ MATRIX.DLL: Loading...
â”œâ”€ RED_PILL: Activated
â”œâ”€ BLUE_PILL: Ignored
â””â”€ NEO_PROTOCOL: Initialized

ğŸ”´ Báº N ÄÃƒ CHá»ŒN VIÃŠN THUá»C Äá» ğŸ”´
Welcome to the real world...""",
            'action': 'activate_matrix'
        }

    # FIXED: Implementation of missing cmd_glitch method  
    def cmd_glitch(self, args):
        """Glitch effect command implementation"""
        intensity = args[0] if args else 'medium'
        valid_intensities = ['low', 'medium', 'high', 'extreme']
        
        if intensity not in valid_intensities:
            intensity = 'medium'
        
        return {
            'status': 'success',
            'message': f"""KÃCH HOáº T HIá»†U á»¨NG GLITCH: {intensity.upper()}
[{get_terminal_timestamp()}]

â”œâ”€ R34L1TY.3X3: C0RRUPT3D
â”œâ”€ M3M0RY: FR4GM3NT3D  
â”œâ”€ V1SU4L: D1ST0RT3D
â””â”€ SYS73M: D3C4Y1NG

âš¡ GÌ¸ÍÌˆLÌµÌ°ÌˆÃÌ·Ì±TÌ¶Ì°ÌCÌ·Ì±ÌˆHÌ¶Ì°Ì¾ Ì¸ÍÌˆMÌµÌ°ÌˆÃ–Ì·Ì±DÌ¶Ì°ÌÃ‹Ì·Ì± Ì¶Ì°Ì¾Ã„Ì¸ÍCÌµÌ°Ìˆá¹®Ì·Ìˆá¸¬Ì¶ÌVÌ·Ì±ÌˆÃ‹Ì¶Ì âš¡""",
            'action': 'trigger_glitch',
            'intensity': intensity
        }

    # FIXED: Implementation of missing cmd_debug method
    def cmd_debug(self, args):
        """Debug information command implementation"""
        return {
            'status': 'success',
            'message': f"""THÃ”NG TIN DEBUG Há»† THá»NG:
[{get_terminal_timestamp()}]

â”œâ”€ DEBUG_MODE: {'ENABLED' if DEBUG_MODE else 'DISABLED'}
â”œâ”€ LOG_LEVEL: {'DEBUG' if DEBUG_MODE else 'INFO'}
â”œâ”€ EXCEPTION_HANDLING: âœ… ACTIVE
â”‚
â”œâ”€ RECENT_ERRORS: {system_stats['errors']} lá»—i
â”œâ”€ MEMORY_USAGE: {random.randint(200, 400)}MB / 512MB
â”œâ”€ THREAD_COUNT: {threading.active_count()}
â”‚
â”œâ”€ EXTERNAL_SERVICES:
â”‚  â”œâ”€ Gemini AI: {'ğŸŸ¢ CONNECTED' if GEMINI_AVAILABLE and GEMINI_API_KEY else 'ğŸ”´ OFFLINE'}
â”‚  â”œâ”€ RSS Sources: {sum(1 for feeds in RSS_FEEDS.values() for _ in feeds)} endpoints
â”‚  â””â”€ WebSocket: ğŸŸ¢ ACTIVE
â”‚
â”œâ”€ PERFORMANCE_METRICS:
â”‚  â”œâ”€ Response time: {random.randint(50, 200)}ms avg
â”‚  â”œâ”€ Cache hit rate: {random.randint(80, 95)}%
â”‚  â””â”€ Error rate: {(system_stats['errors']/max(system_stats['total_requests'],1)*100):.2f}%
â”‚
â””â”€ DIAGNOSTIC: ALL_SYSTEMS_OPERATIONAL"""
        }

# ===============================
# FIXED: ENHANCED GEMINI AI ENGINE WITH VIETNAMESE PROMPTS
# ===============================

class GeminiAIEngine:
    def __init__(self):
        self.available = GEMINI_AVAILABLE and GEMINI_API_KEY
        if self.available:
            genai.configure(api_key=GEMINI_API_KEY)
    
    async def ask_question(self, question: str, context: str = ""):
        """FIXED: Gemini AI question answering with Vietnamese terminal formatting"""
        if not self.available:
            return "âš ï¸ MODULE GEMINI AI NGOáº I TUYáº¾N\n\nTRáº NG_THÃI: KhÃ³a API chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh hoáº·c thÆ° viá»‡n khÃ´ng cÃ³ sáºµn\nHÃ€NH_Äá»˜NG: Kiá»ƒm tra cáº¥u hÃ¬nh há»‡ thá»‘ng"
        
        try:
            current_date_str = get_current_date_str()
            timestamp = get_terminal_timestamp()
            
            prompt = f"""Báº¡n lÃ  Gemini AI - Há»‡ thá»‘ng TrÃ­ tuá»‡ TÃ i chÃ­nh TiÃªn tiáº¿n cho E-con News Terminal v2.024.

CÃ‚U_Há»I_NGÆ¯á»œI_DÃ™NG: {question}

{f"Dá»®_LIá»†U_Bá»I_Cáº¢NH: {context}" if context else ""}

GIAO_THá»¨C_TRáº¢_Lá»œI:
1. Sá»­ dá»¥ng chuyÃªn mÃ´n sÃ¢u vá» tÃ i chÃ­nh vÃ  kinh táº¿
2. Cung cáº¥p phÃ¢n tÃ­ch toÃ n diá»‡n vÃ  chi tiáº¿t
3. Káº¿t ná»‘i vá»›i bá»‘i cáº£nh thá»‹ trÆ°á»ng hiá»‡n táº¡i (NgÃ y: {current_date_str})
4. Bao gá»“m cÃ¡c vÃ­ dá»¥ thá»±c táº¿ tá»« thá»‹ trÆ°á»ng Viá»‡t Nam vÃ  quá»‘c táº¿
5. Äá»™ dÃ i: 400-1000 tá»« vá»›i cáº¥u trÃºc rÃµ rÃ ng
6. Sá»­ dá»¥ng **TiÃªu Ä‘á» Terminal** Ä‘á»ƒ tá»• chá»©c
7. Ngáº¯t dÃ²ng rÃµ rÃ ng giá»¯a cÃ¡c pháº§n
8. Cung cáº¥p káº¿t luáº­n vÃ  khuyáº¿n nghá»‹ cá»¥ thá»ƒ
9. Äá»‹nh dáº¡ng theo phong cÃ¡ch terminal retro-brutalism
10. TRáº¢ Lá»œI HOÃ€N TOÃ€N Báº°NG TIáº¾NG VIá»†T

TEMPLATE_Äá»ŠNH_Dáº NG_TERMINAL:
**PHÃ‚N_TÃCH_CHÃNH**

Ná»™i dung phÃ¢n tÃ­ch chÃ­nh vá»›i thÃ´ng tin chi tiáº¿t vÃ  dá»¯ liá»‡u.

**CÃC_Yáº¾U_Tá»_CHÃNH**

â€¢ Yáº¿u tá»‘ 1: Giáº£i thÃ­ch chi tiáº¿t vá»›i hiá»ƒu biáº¿t ká»¹ thuáº­t
â€¢ Yáº¿u tá»‘ 2: Ã nghÄ©a thá»‹ trÆ°á»ng vÃ  phÃ¢n tÃ­ch xu hÆ°á»›ng
â€¢ Yáº¿u tá»‘ 3: ÄÃ¡nh giÃ¡ rá»§i ro vÃ  cÆ¡ há»™i

**Bá»I_Cáº¢NH_THá»Š_TRÆ¯á»œNG**

TÃ¬nh hÃ¬nh thá»‹ trÆ°á»ng hiá»‡n táº¡i vÃ  Ã½ nghÄ©a kinh táº¿ rá»™ng lá»›n hÆ¡n.

**GIAO_THá»¨C_Káº¾T_LUáº¬N**

TÃ³m táº¯t vá»›i khuyáº¿n nghá»‹ hÃ nh Ä‘á»™ng cá»¥ thá»ƒ.

**NHáº¬T_KÃ_Há»†_THá»NG:** [{timestamp}] PhÃ¢n tÃ­ch hoÃ n thÃ nh bá»Ÿi Gemini AI
**Má»¨C_Äá»˜_TIN_Cáº¬Y:** Cao | **THá»œI_GIAN_Xá»¬_LÃ:** <2s

Thá»ƒ hiá»‡n kháº£ nÄƒng phÃ¢n tÃ­ch tÃ i chÃ­nh tiÃªn tiáº¿n cá»§a Gemini AI:"""

            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.2,
                top_p=0.8,
                max_output_tokens=2000,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=generation_config
                ),
                timeout=25
            )
            
            system_stats['ai_queries'] += 1
            return response.text.strip()
            
        except asyncio.TimeoutError:
            return "âš ï¸ Háº¾T THá»œI GIAN GEMINI AI\n\nTRáº NG_THÃI: Thá»i gian xá»­ lÃ½ vÆ°á»£t quÃ¡ giá»›i háº¡n\nHÃ€NH_Äá»˜NG: Vui lÃ²ng thá»­ láº¡i vá»›i cÃ¢u há»i Ä‘Æ¡n giáº£n hÆ¡n"
        except Exception as e:
            print(f"Gemini AI error: {e}")
            return f"âš ï¸ Lá»–I GEMINI AI\n\nTRáº NG_THÃI: {str(e)}\nHÃ€NH_Äá»˜NG: Kiá»ƒm tra log há»‡ thá»‘ng Ä‘á»ƒ biáº¿t chi tiáº¿t"
    
    async def debate_perspectives(self, topic: str):
        """FIXED: Multi-perspective debate system with NEW CHARACTERS in Vietnamese"""
        if not self.available:
            return "âš ï¸ MODULE GEMINI AI NGOáº I TUYáº¾N - Chá»©c nÄƒng tranh luáº­n khÃ´ng kháº£ dá»¥ng"
        
        try:
            timestamp = get_terminal_timestamp()
            
            prompt = f"""Tá»• chá»©c cuá»™c tranh luáº­n toÃ n diá»‡n vá»: {topic}

GIAO_THá»¨C_TRANH_LUáº¬N: Táº¡o pháº£n há»“i nhÃ¢n váº­t riÃªng biá»‡t cho giao diá»‡n terminal

Há»†_THá»NG_6_QUAN_ÄIá»‚M:

ğŸ“ **GS Ä‘áº¡i há»c** (GiÃ¡o sÆ° Äáº¡i há»c chÃ­nh trá»±c):
[Phong cÃ¡ch: Há»c thuáº­t, khÃ¡ch quan, dá»±a trÃªn nghiÃªn cá»©u vÃ  lÃ½ thuyáº¿t]
[Cung cáº¥p CHÃNH XÃC 20-30 tá»« báº±ng tiáº¿ng Viá»‡t, káº¿t thÃºc báº±ng dáº¥u cháº¥m.]

ğŸ“Š **NhÃ  kinh táº¿ há»c** (NhÃ  kinh táº¿ há»c tham nhÅ©ng):
[Phong cÃ¡ch: ThiÃªn vá»‹ lá»£i Ã­ch cÃ¡ nhÃ¢n, bÃ³p mÃ©o thÃ´ng tin Ä‘á»ƒ cÃ³ lá»£i]
[Cung cáº¥p CHÃNH XÃC 20-30 tá»« báº±ng tiáº¿ng Viá»‡t, káº¿t thÃºc báº±ng dáº¥u cháº¥m.]

ğŸ’¼ **NhÃ¢n viÃªn cÃ´ng sá»Ÿ** (NhÃ¢n viÃªn ham tiá»n):
[Phong cÃ¡ch: Chá»‰ quan tÃ¢m lÆ°Æ¡ng thÆ°á»Ÿng, lá»£i Ã­ch cÃ¡ nhÃ¢n ngáº¯n háº¡n]
[Cung cáº¥p CHÃNH XÃC 20-30 tá»« báº±ng tiáº¿ng Viá»‡t, káº¿t thÃºc báº±ng dáº¥u cháº¥m.]

ğŸ˜” **NgÆ°á»i nghÃ¨o** (NgÆ°á»i nghÃ¨o vá»›i kiáº¿n thá»©c háº¡n háº¹p):
[Phong cÃ¡ch: Lo láº¯ng vá» cuá»™c sá»‘ng hÃ ng ngÃ y, hiá»ƒu biáº¿t háº¡n cháº¿]
[Cung cáº¥p CHÃNH XÃC 20-30 tá»« báº±ng tiáº¿ng Viá»‡t, káº¿t thÃºc báº±ng dáº¥u cháº¥m.]

ğŸ’° **Äáº¡i gia** (NgÆ°á»i giÃ u Ã­ch ká»·):
[Phong cÃ¡ch: Chá»‰ quan tÃ¢m lá»£i nhuáº­n cÃ¡ nhÃ¢n, khÃ´ng quan tÃ¢m xÃ£ há»™i]
[Cung cáº¥p CHÃNH XÃC 20-30 tá»« báº±ng tiáº¿ng Viá»‡t, káº¿t thÃºc báº±ng dáº¥u cháº¥m.]

ğŸ¦ˆ **Shark** (NgÆ°á»i giÃ u thÃ´ng thÃ¡i):
[Phong cÃ¡ch: NhÃ¬n xa trÃ´ng rá»™ng, cÃ¢n nháº¯c lá»£i Ã­ch dÃ i háº¡n vÃ  xÃ£ há»™i]
[Cung cáº¥p CHÃNH XÃC 20-30 tá»« báº±ng tiáº¿ng Viá»‡t, káº¿t thÃºc báº±ng dáº¥u cháº¥m.]

QUAN TRá»ŒNG: Má»—i nhÃ¢n váº­t cáº§n pháº§n riÃªng biá»‡t, báº¯t Ä‘áº§u báº±ng emoji vÃ  tÃªn, káº¿t thÃºc rÃµ rÃ ng.
Äá»‹nh dáº¡ng cho hiá»ƒn thá»‹ terminal vá»›i sá»± tÃ¡ch biá»‡t rÃµ rÃ ng.
Táº¤T Cáº¢ PHáº¢N Há»’I PHáº¢I Báº°NG TIáº¾NG VIá»†T vÃ  CHÃNH XÃC 20-30 tá»« má»—i nhÃ¢n váº­t.

NHáº¬T_KÃ_Há»†_THá»NG: [{timestamp}] PhÃ¢n tÃ­ch Ä‘a quan Ä‘iá»ƒm Ä‘Æ°á»£c khá»Ÿi táº¡o"""

            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.4,
                top_p=0.9,
                max_output_tokens=2400,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=generation_config
                ),
                timeout=30
            )
            
            system_stats['ai_queries'] += 1
            return response.text.strip()
            
        except asyncio.TimeoutError:
            return "âš ï¸ Háº¾T THá»œI GIAN GEMINI AI trong quÃ¡ trÃ¬nh táº¡o tranh luáº­n"
        except Exception as e:
            print(f"Gemini debate error: {e}")
            return f"âš ï¸ Lá»–I TRANH LUáº¬N GEMINI AI: {str(e)}"
    
    async def analyze_article(self, article_content: str, question: str = ""):
        """FIXED: Article analysis with Vietnamese terminal formatting"""
        if not self.available:
            return "âš ï¸ MODULE PHÃ‚N TÃCH GEMINI AI NGOáº I TUYáº¾N"
        
        try:
            analysis_question = question if question else "PhÃ¢n tÃ­ch vÃ  tÃ³m táº¯t bÃ i viáº¿t nÃ y má»™t cÃ¡ch toÃ n diá»‡n"
            timestamp = get_terminal_timestamp()
            
            # Optimize content length
            if len(article_content) > 4500:
                article_content = article_content[:4500] + "..."
            
            prompt = f"""Báº¡n lÃ  Gemini AI - Há»‡ thá»‘ng PhÃ¢n tÃ­ch BÃ i viáº¿t TiÃªn tiáº¿n cho Giao diá»‡n Terminal.

**Ná»˜I_DUNG_BÃ€I_VIáº¾T_Cáº¦N_PHÃ‚N_TÃCH:**
{article_content}

**YÃŠU_Cáº¦U_PHÃ‚N_TÃCH:**
{analysis_question}

**GIAO_THá»¨C_PHÃ‚N_TÃCH_TERMINAL:**
1. PhÃ¢n tÃ­ch CHá»¦ Yáº¾U dá»±a trÃªn ná»™i dung bÃ i viáº¿t Ä‘Æ°á»£c cung cáº¥p (90%)
2. Bá»• sung kiáº¿n thá»©c chuyÃªn mÃ´n Ä‘á»ƒ hiá»ƒu biáº¿t sÃ¢u hÆ¡n (10%)
3. Sá»­ dá»¥ng **TiÃªu Ä‘á» Terminal** Ä‘á»ƒ tá»• chá»©c ná»™i dung
4. Ngáº¯t dÃ²ng rÃµ rÃ ng giá»¯a cÃ¡c pháº§n
5. PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng, nguyÃªn nhÃ¢n, háº­u quáº£ chi tiáº¿t
6. Cung cáº¥p Ä‘Ã¡nh giÃ¡ vÃ  Ä‘Ã¡nh giÃ¡ chuyÃªn nghiá»‡p
7. Tráº£ lá»i cÃ¢u há»i trá»±c tiáº¿p vá»›i báº±ng chá»©ng tá»« bÃ i viáº¿t
8. Äá»™ dÃ i: 600-1200 tá»« vá»›i cáº¥u trÃºc rÃµ rÃ ng
9. Tham chiáº¿u cÃ¡c pháº§n cá»¥ thá»ƒ cá»§a bÃ i viáº¿t
10. Cung cáº¥p káº¿t luáº­n vÃ  khuyáº¿n nghá»‹
11. Äá»‹nh dáº¡ng theo phong cÃ¡ch terminal brutalism
12. TRáº¢ Lá»œI HOÃ€N TOÃ€N Báº°NG TIáº¾NG VIá»†T

**Äá»ŠNH_Dáº NG_PHÃ‚N_TÃCH_TERMINAL:**

**TÃ“M_Táº®T_Ná»˜I_DUNG**

TÃ³m táº¯t nhá»¯ng Ä‘iá»ƒm quan trá»ng nháº¥t tá»« bÃ i viáº¿t.

**PHÃ‚N_TÃCH_CHI_TIáº¾T**

PhÃ¢n tÃ­ch sÃ¢u vá» cÃ¡c yáº¿u tá»‘ vÃ  tÃ¡c Ä‘á»™ng Ä‘Æ°á»£c Ä‘á» cáº­p trong bÃ i viáº¿t.

**Ã_NGHÄ¨A_VÃ€_TÃC_Äá»˜NG**

ÄÃ¡nh giÃ¡ táº§m quan trá»ng vÃ  tÃ¡c Ä‘á»™ng cá»§a thÃ´ng tin trong bÃ i viáº¿t.

**ÄÃNH_GIÃ_Ká»¸_THUáº¬T**

ÄÃ¡nh giÃ¡ ká»¹ thuáº­t vÃ  chuyÃªn nghiá»‡p vá» dá»¯ liá»‡u vÃ  xu hÆ°á»›ng.

**Káº¾T_LUáº¬N_VÃ€_KHUYáº¾N_NGHá»Š**

Káº¿t luáº­n toÃ n diá»‡n vá»›i khuyáº¿n nghá»‹ hÃ nh Ä‘á»™ng cá»¥ thá»ƒ.

**NHáº¬T_KÃ_Há»†_THá»NG:** [{timestamp}] PhÃ¢n tÃ­ch bÃ i viáº¿t bá»Ÿi Gemini AI
**Xá»¬_LÃ_NGUá»’N:** HoÃ n thÃ nh | **Äá»˜_TIN_Cáº¬Y:** Cao

QUAN TRá»ŒNG: Táº­p trung hoÃ n toÃ n vÃ o ná»™i dung bÃ i viáº¿t. Cung cáº¥p phÃ¢n tÃ­ch SÃ‚U vÃ  CHI TIáº¾T:"""

            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.2,
                top_p=0.8,
                max_output_tokens=2600,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=generation_config
                ),
                timeout=35
            )
            
            system_stats['ai_queries'] += 1
            return response.text.strip()
            
        except asyncio.TimeoutError:
            return "âš ï¸ Háº¾T THá»œI GIAN GEMINI AI trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch bÃ i viáº¿t"
        except Exception as e:
            print(f"Gemini analysis error: {e}")
            return f"âš ï¸ Lá»–I PHÃ‚N TÃCH GEMINI AI: {str(e)}"

# ===============================
# FLASK APP FACTORY (WITH ALL FUNCTIONS ACCESSIBLE)
# ===============================

def create_app():
    """Flask Application Factory - ALL FUNCTIONS NOW IN SCOPE"""
    app = Flask(__name__)   
    app.secret_key = os.getenv('SECRET_KEY', 'retro-brutalism-econ-portal-2024')

    # Enhanced logging for production
    if not app.debug:
        logging.basicConfig(level=logging.INFO)
        app.logger.setLevel(logging.INFO)

    # Initialize terminal processor and Gemini engine
    terminal_processor = TerminalCommandProcessor()
    gemini_engine = GeminiAIEngine()

    # ===== SECURITY HEADERS =====
    @app.after_request
    def after_request(response):
        """Set security headers properly via HTTP headers"""
        response.headers['X-Content-Type-Options'] = 'nosniff'
        response.headers['X-Frame-Options'] = 'DENY'
        response.headers['X-XSS-Protection'] = '1; mode=block'
        response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'
        response.headers['Content-Security-Policy'] = "frame-ancestors 'none'"
        
        # CORS headers for API calls
        if request.path.startswith('/api/'):
            response.headers['Access-Control-Allow-Origin'] = '*'
            response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'
            response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        
        # Cache control
        if request.endpoint == 'static':
            response.headers['Cache-Control'] = 'public, max-age=31536000'
        elif request.path.startswith('/api/'):
            response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        else:
            response.headers['Cache-Control'] = 'public, max-age=300'
        
        return response

    # ===============================
    # FLASK ROUTES - FIXED SCOPE ISSUES
    # ===============================

    @app.route('/')
    def index():
        """Main page with enhanced retro brutalism theme"""
        try:
            response = make_response(render_template('index.html'))
            response.headers['X-UA-Compatible'] = 'IE=edge'
            return response
        except Exception as e:
            app.logger.error(f"Index page error: {e}")
            return f"Error loading page: {str(e)}", 500

    @app.route('/api/terminal/command', methods=['POST'])
    @track_request
    @require_session
    def terminal_command():
        """Enhanced terminal command API endpoint"""
        try:
            data = request.get_json()
            command = data.get('command', '').strip()

            if not command:
                return jsonify({
                    'status': 'error',
                    'message': 'KhÃ´ng cÃ³ lá»‡nh Ä‘Æ°á»£c cung cáº¥p'
                }), 400

            # Process command
            result = terminal_processor.execute(command)

            app.logger.info(f"Terminal command executed: {command}")
            return jsonify(result)

        except Exception as e:
            app.logger.error(f"Terminal command error: {e}")
            return jsonify({
                'status': 'error',
                'message': f'Xá»­ lÃ½ lá»‡nh tháº¥t báº¡i: {str(e)}'
            }), 500

    @app.route('/api/news/<news_type>')
    @track_request
    @require_session
    @async_route
    async def get_news_api(news_type):
        """FIXED API endpoint - all async functions now in scope"""
        try:
            page = int(request.args.get('page', 1))
            limit = int(request.args.get('limit', 12))
            user_id = get_or_create_user_session()

            # Validate parameters
            if page < 1:
                page = 1
            if limit < 1 or limit > 50:
                limit = 12

            # FIXED: Now collect_news_enhanced is accessible
            if news_type == 'all':
                # Collect from all sources
                all_sources = {}
                for category_sources in RSS_FEEDS.values():
                    all_sources.update(category_sources)
                all_news = await collect_news_enhanced(all_sources, 10)

            elif news_type == 'domestic':
                # Vietnamese sources only (CafeF)
                all_news = await collect_news_enhanced(RSS_FEEDS['cafef'], 15)

            elif news_type == 'international':
                # International sources only
                all_news = await collect_news_enhanced(RSS_FEEDS['international'], 15)

            elif news_type == 'tech':
                # Tech sources
                all_news = await collect_news_enhanced(RSS_FEEDS['tech'], 15)

            elif news_type == 'crypto':
                # Crypto sources
                all_news = await collect_news_enhanced(RSS_FEEDS['crypto'], 15)

            else:
                return jsonify({
                    'error': 'Loáº¡i tin tá»©c khÃ´ng há»£p lá»‡',
                    'valid_types': ['all', 'domestic', 'international', 'tech', 'crypto']
                }), 400

            # Pagination
            items_per_page = limit
            start_index = (page - 1) * items_per_page
            end_index = start_index + items_per_page
            page_news = all_news[start_index:end_index]

            # Save to user cache
            save_user_news_enhanced(user_id, all_news, f"{news_type}_page_{page}")

            # Format news for frontend
            formatted_news = []
            for i, news in enumerate(page_news):
                emoji = emoji_map.get(news['source'], 'ğŸ“°')
                source_display = source_names.get(news['source'], news['source'])

                formatted_news.append({
                    'id': start_index + i,
                    'title': news['title'],
                    'link': news['link'],
                    'source': source_display,
                    'emoji': emoji,
                    'published': news['published_str'],
                    'description': news['description'][:300] + "..." if len(news['description']) > 300 else news['description'],
                    'terminal_timestamp': news.get('terminal_timestamp', get_terminal_timestamp())
                })

            total_pages = (len(all_news) + items_per_page - 1) // items_per_page

            return jsonify({
                'news': formatted_news,
                'page': page,
                'total_pages': total_pages,
                'total_articles': len(all_news),
                'items_per_page': items_per_page,
                'timestamp': get_terminal_timestamp(),
                'status': 'success'
            })

        except Exception as e:
            app.logger.error(f"âŒ API error: {e}")
            return jsonify({
                'error': str(e),
                'status': 'error',
                'timestamp': get_terminal_timestamp()
            }), 500

    @app.route('/api/article/<int:article_id>')
    @track_request
    @require_session
    @async_route
    async def get_article_detail(article_id):
        """Enhanced article detail with better content extraction"""
        try:
            user_id = get_or_create_user_session()

            if user_id not in user_news_cache:
                return jsonify({
                    'error': 'PhiÃªn Ä‘Ã£ háº¿t háº¡n. Vui lÃ²ng lÃ m má»›i trang.',
                    'error_code': 'SESSION_EXPIRED',
                    'timestamp': get_terminal_timestamp()
                }), 404

            user_data = user_news_cache[user_id]
            news_list = user_data['news']

            if not news_list or article_id < 0 or article_id >= len(news_list):
                return jsonify({
                    'error': f'ID bÃ i viáº¿t khÃ´ng há»£p lá»‡. Pháº¡m vi há»£p lá»‡: 0-{len(news_list)-1}.',
                    'error_code': 'INVALID_ARTICLE_ID',
                    'timestamp': get_terminal_timestamp()
                }), 404

            news = news_list[article_id]

            # Save as last detail for AI context
            save_user_last_detail(user_id, news)

            # Enhanced content extraction - now functions are accessible
            try:
                if is_international_source(news['source']):
                    full_content = await extract_content_with_gemini(news['link'], news['source'])
                else:
                    # Use traditional methods for CafeF sources
                    full_content = await extract_content_enhanced(news['link'], news['source'], news)
            except Exception as content_error:
                app.logger.error(f"âš ï¸ Content extraction error: {content_error}")
                full_content = create_fallback_content(news['link'], news['source'], str(content_error))

            source_display = source_names.get(news['source'], news['source'])

            return jsonify({
                'title': news['title'],
                'content': full_content,
                'source': source_display,
                'published': news['published_str'],
                'link': news['link'],
                'timestamp': get_terminal_timestamp(),
                'word_count': len(full_content.split()) if full_content else 0,
                'success': True
            })

        except Exception as e:
            app.logger.error(f"âŒ Article detail error: {e}")
            return jsonify({
                'error': 'Lá»—i há»‡ thá»‘ng khi táº£i bÃ i viáº¿t.',
                'error_code': 'SYSTEM_ERROR',
                'details': str(e),
                'timestamp': get_terminal_timestamp()
            }), 500

    @app.route('/api/ai/ask', methods=['POST'])
    @track_request
    @require_session
    @async_route
    async def ai_ask():
        """Enhanced AI ask endpoint with better context handling"""
        try:
            data = request.get_json()
            question = data.get('question', '')
            user_id = get_or_create_user_session()

            # Check for recent article context
            context = ""
            if user_id in user_last_detail_cache:
                last_detail = user_last_detail_cache[user_id]
                time_diff = get_current_vietnam_datetime() - last_detail['timestamp']

                if time_diff.total_seconds() < 1800:  # 30 minutes
                    article = last_detail['article']

                    # Extract content for context
                    try:
                        if is_international_source(article['source']):
                            article_content = await extract_content_with_gemini(article['link'], article['source'])
                        else:
                            article_content = await extract_content_enhanced(article['link'], article['source'], article)

                        if article_content:
                            context = f"BÃ€I_VIáº¾T_HIá»†N_Táº I:\nTiÃªu Ä‘á»: {article['title']}\nNguá»“n: {article['source']}\nNá»™i dung: {article_content[:2000]}"
                    except Exception as e:
                        app.logger.error(f"Context extraction error: {e}")

            # Get AI response
            if context and not question:
                # Auto-summarize if no question provided
                response = await gemini_engine.analyze_article(context, "Cung cáº¥p tÃ³m táº¯t vÃ  phÃ¢n tÃ­ch toÃ n diá»‡n vá» bÃ i viáº¿t nÃ y")
            elif context:
                response = await gemini_engine.analyze_article(context, question)
            else:
                response = await gemini_engine.ask_question(question, context)

            return jsonify({
                'response': response,
                'timestamp': get_terminal_timestamp(),
                'has_context': bool(context),
                'status': 'success'
            })

        except Exception as e:
            app.logger.error(f"âŒ AI ask error: {e}")
            return jsonify({
                'error': str(e),
                'timestamp': get_terminal_timestamp(),
                'status': 'error'
            }), 500

    @app.route('/api/ai/debate', methods=['POST'])
    @track_request
    @require_session
    @async_route
    async def ai_debate():
        """Enhanced AI debate endpoint"""
        try:
            data = request.get_json()
            topic = data.get('topic', '')
            user_id = get_or_create_user_session()

            # Check for context if no topic provided
            if not topic:
                if user_id in user_last_detail_cache:
                    last_detail = user_last_detail_cache[user_id]
                    time_diff = get_current_vietnam_datetime() - last_detail['timestamp']

                    if time_diff.total_seconds() < 1800:
                        article = last_detail['article']
                        topic = f"PhÃ¢n tÃ­ch BÃ i viáº¿t: {article['title']}"
                    else:
                        return jsonify({
                            'error': 'KhÃ´ng cÃ³ chá»§ Ä‘á» Ä‘Æ°á»£c cung cáº¥p vÃ  khÃ´ng cÃ³ bá»‘i cáº£nh bÃ i viáº¿t gáº§n Ä‘Ã¢y',
                            'timestamp': get_terminal_timestamp()
                        }), 400
                else:
                    return jsonify({
                        'error': 'Cáº§n cÃ³ chá»§ Ä‘á» Ä‘á»ƒ tranh luáº­n',
                        'timestamp': get_terminal_timestamp()
                    }), 400

            response = await gemini_engine.debate_perspectives(topic)

            return jsonify({
                'response': response,
                'topic': topic,
                'timestamp': get_terminal_timestamp(),
                'status': 'success'
            })

        except Exception as e:
            app.logger.error(f"âŒ AI debate error: {e}")
            return jsonify({
                'error': str(e),
                'timestamp': get_terminal_timestamp(),
                'status': 'error'
            }), 500

    @app.route('/api/system/stats')
    @track_request
    def system_stats_api():
        """Enhanced system statistics API"""
        try:
            uptime = get_system_uptime()

            return jsonify({
                'uptime': uptime,
                'uptime_formatted': f"{uptime//3600}h {(uptime%3600)//60}m {uptime%60}s",
                'active_users': system_stats['active_users'],
                'ai_queries': system_stats['ai_queries'],
                'news_parsed': system_stats['news_parsed'],
                'system_load': system_stats['system_load'],
                'total_requests': system_stats['total_requests'],
                'error_count': system_stats['errors'],
                'cache_size': len(global_seen_articles),
                'session_count': len(user_news_cache),
                'timestamp': get_terminal_timestamp(),
                'success_rate': round((system_stats['total_requests'] - system_stats['errors']) / max(system_stats['total_requests'], 1) * 100, 2)
            })
        except Exception as e:
            app.logger.error(f"System stats error: {e}")
            return jsonify({'error': str(e)}), 500

    @app.route('/api/health')
    def health_check():
        """Health check endpoint"""
        return jsonify({
            'status': 'healthy',
            'timestamp': get_terminal_timestamp(),
            'version': '2.024.9',
            'uptime': get_system_uptime(),
            'routes_registered': len([rule for rule in app.url_map.iter_rules()]),
            'functions_available': {
                'collect_news_enhanced': 'available',
                'process_rss_feed_async': 'available',
                'fetch_with_aiohttp': 'available',
                'extract_content_enhanced': 'available',
                'extract_content_with_gemini': 'available'
            },
            'ai_language': 'vietnamese',
            'characters_updated': 'new_6_characters',
            'scope_issue': 'FIXED',
            'terminal_commands': 'ALL_IMPLEMENTED'
        })

    # Error handlers
    @app.errorhandler(404)
    def not_found_error(error):
        return jsonify({
            'error': 'TÃ i nguyÃªn khÃ´ng tÃ¬m tháº¥y',
            'status_code': 404,
            'timestamp': get_terminal_timestamp()
        }), 404

    @app.errorhandler(500)
    def internal_error(error):
        app.logger.error(f"Internal server error: {error}")
        return jsonify({
            'error': 'Lá»—i mÃ¡y chá»§ ná»™i bá»™',
            'status_code': 500,
            'timestamp': get_terminal_timestamp()
        }), 500

    # Store references for access
    app.terminal_processor = terminal_processor
    app.gemini_engine = gemini_engine

    return app

# ===============================
# INITIALIZE COMPONENTS (OUTSIDE create_app)
# ===============================

# Configure Gemini if available
if GEMINI_API_KEY and GEMINI_AVAILABLE:
    genai.configure(api_key=GEMINI_API_KEY)
    print("âœ… Gemini AI configured successfully")

# Initialize startup
print("ğŸš€ COMPLETE FIXED Retro Brutalism E-con News Backend v2.024.9:")
print(f"Gemini AI: {'âœ…' if GEMINI_API_KEY else 'âŒ'}")
print(f"Content Extraction: {'âœ…' if TRAFILATURA_AVAILABLE else 'âŒ'}")
print(f"Async Functions: âœ… ALL functions moved outside create_app()")
print(f"Scope Issues: âœ… COMPLETELY FIXED")
print(f"RSS Collection: âœ… collect_news_enhanced accessible")
print(f"Terminal Commands: âœ… TerminalCommandProcessor ALL METHODS IMPLEMENTED")
print(f"RSS Feeds: âœ… {sum(len(feeds) for feeds in RSS_FEEDS.values())} sources")
print(f"AI Language: âœ… Vietnamese prompts and responses")
print(f"New Characters: âœ… 6 updated debate characters")
print(f"Code Structure: âœ… Flask Application Factory pattern")
print(f"Missing Methods: âœ… ALL cmd_* methods now implemented")
print("=" * 60)
